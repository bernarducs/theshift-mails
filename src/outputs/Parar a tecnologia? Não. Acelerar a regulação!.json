{"mail_id": 9837, "from": "=?utf-8?Q?The=20Shift?= <news@theshift.info>", "subject": "Parar a tecnologia? Não. Acelerar a regulação!", "date": "2023-03-30T16:07:40+00:00", "body": "O medo da IA ​​fora de controle não é novo. O que é novo é o medo de perder a corrida pela IA.  \r\n\r\n30/03/23  | Abra no browser (https://mailchi.mp/theshift.info/parar-a-tecnologia-no-acelerar-a-regulao?e=43a197caaf)\r\n\r\n\r\n** Futuro do Presente\r\n------------------------------------------------------------\r\n\r\n\r\n**\r\nUM OFERECIMENTO DE\r\n------------------------------------------------------------\r\nhttps://www.appdynamics.com/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D\r\nbernardo, bom dia!\r\nA coisa mais importante sobre a carta divulgada pelo Future of Life Institute, pedindo para interromper o desenvolvimento da IA, é saber QUEM NÃO ASSINOU. É disso que tratamos hoje.\r\n\r\nA carta comete um erro colossal: pedir para parar a tecnologia, ao invés de pedir para acelerar as discussões sobre ética e regulação. E os grandes nomes sérios da IA concordam que é risível sugerir tal freio de arrumação, porque ele é impossível, e sem sentido.\r\n\r\nEm março de 1999, há 24 anos, portanto, foi publicado um trabalho colaborativo chamado \"The Cluetrain Manifesto: the end of business as usual\" (https://cluetrain.com/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , que argumentava que o marketing convencional estava aquém da nova realidade dos consumidores hiperconectados na internet, e as empresas precisavam se mexer. Tinha 95 teses (ou pistas) sobre o assunto.\r\n\r\nDiz o manifesto: \"Uma conversa global poderosa começou. Através da Internet, as pessoas estão descobrindo e inventando novas maneiras de compartilhar conhecimento relevante com uma velocidade estonteante. Como resultado direto, os mercados estão ficando mais inteligentes — e mais inteligentes do que a maioria das empresas\".\r\n\r\nTroque a palavra internet por inteligência artificial no texto acima e você terá a versão século 21 do Cluetrain Manifesto. A carta, assinada por Musk e Harari, para citar alguns signatários, entra na contramão de tudo isso. Por isso somos contra. Há quatro anos a The Shift vem sistematicamente discutindo a importância de acelerar discussões e ações efetivas sobre ética e riscos da IA. Mas jamais você vai nos ver pedir para parar a evolução da tecnologia.\r\nBoa leitura.\r\n\r\n\r\n** Dá para fechar a Caixa de Pandora?\r\n------------------------------------------------------------\r\n\r\nOu colocar o gênio de volta na garrafa? Foi um pouco assim, com um misto de ceticismo (https://www.ciodive.com/news/Open-letter-AI-future-of-life-institute-OpenAI-Microsoft/646358/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e incredulidade (https://www.estadao.com.br/link/cultura-digital/nao-e-possivel-pausar-o-desenvolvimento-de-inteligencia-artificial-dizem-especialistas/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , que muita gente na comunidade científica recebeu a proposta dos signatários da carta do Future of Life Institute (FLI) (https://futureoflife.org/open-letter/pause-giant-ai-experiments/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , incluindo Yuval Harari, Joshua Bengio, Stuart Russell, Elon Musk e Steve Wozniak, de uma pausa imediata no treinamento de sistemas de IA mais poderosos que o GPT-4 por ao menos seis meses, até que se desenvolva e implemente um conjunto de protocolos de segurança compartilhados para design e desenvolvimento avançado da tecnologia.\r\n\r\nNinguém é contra ao estabelecimento de regras para o desenvolvimento e uso da IA. Nem os adventistas como Bill Gates, como bem pontuou o advogado Ronaldo Lemos (https://www1.folha.uol.com.br/colunas/ronaldolemos/2023/03/harari-e-o-medo-das-inteligencias-artificiais.shtml?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D#comentarios) , ao desenhar os dois campos que começam a se estabelecer no debate sobre a tecnologia — Elon Musk e Yuval Harari lideram os apocalípticos. O que soou estranho foi a crença de que é possível parar.\r\n\r\n\"É uma péssima ideia. Não há uma maneira realista de implementar uma moratória e impedir que todas as equipes ampliem os LLMs, a menos que os governos intervenham\", argumentou Andrew Ng (https://www.linkedin.com/posts/andrewyng_the-call-for-a-6-month-moratorium-on-making-activity-7046909992645394432-s7_X?utm_source=share&utm_medium=member_desktop&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , um dos nomes mais respeitados da indústria de IA, cofundador e chefe do Google Brain, ex-cientista-chefe da Baidu, professor adjunto na Universidade de Stanford, cofundador do Coursera e do deeplearning.ai.\r\n\r\n\"Para promover a segurança da IA, os regulamentos em torno da transparência e da auditoria seriam mais práticos e fariam uma diferença maior\", diz Ng. Está certo. É essencial concentrar esforços na criação de estruturas de governança de IA responsáveis que possam orientar o desenvolvimento e a implantação dessas tecnologias. Acelerar a regulação!\r\n\r\nQue há riscos imprevisíveis com a IA, todos sabemos. O difícil é acreditar no pedido de socorro de uma associação \"longodeterminística\" (https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)  e financiada por quem ataca direitos e despreza discussões sobre danos e efeitos da tecnologia (https://futurism.com/elon-musk-backed-future-of-life-institute-gives-out-7-million-in-funding-to-keep-ai-safe?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) há muito tempo, como Musk. E que, no comando do Twitter, tem tomado mais atitudes em prol da disseminação de desinformação do que contra. Será que ele concorda com a regulação das plataformas de social media? Não deveria estar fazendo mais para usar a IA na luta contra a desinformação? Infelizmente, regulação das plataformas e a regulação da IA não são assuntos tão desconexos como muita gente supõe. E a parada proposta afetaria também a Tesla (https://www.barrons.com/articles/musk-tesla-ai-letter-?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) ?\r\n\r\nOK. Tem gente graúda entre os signatários da carta, como a cientista da computação Timnit Gebru (https://stanforddaily.com/2023/02/15/utopia-for-whom-timnit-gebru-on-the-dangers-of-artificial-general-intelligence/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , demitida de seu cargo como colíder da equipe de pesquisa de IA ética do Google, após se recusar a deixar de publicar um artigo sobre os perigos dos grandes modelos de linguagem. Gary Marcus, professor de psicologia e ciência neural na Universidade de Nova York, disse à Reuters (https://www.reuters.com/technology/musk-experts-urge-pause-training-ai-systems-that-can-outperform-gpt-4-2023-03-29/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) que “a carta não é perfeita, mas o espírito está certo”. Da mesma forma, Emad Mostaque, o CEO da Stability.AI, que colocou sua empresa contra a OpenAI, como uma empresa de IA verdadeiramente \"aberta\", twittou (https://twitter.com/EMostaque/status/1641076537608003584?s=20&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) : “Então, sim, não acho que uma pausa de seis meses seja a melhor ideia, nem concordo com tudo, mas há algumas coi\r\nsas interessantes nessa carta\". Claro que há. Sobretudo em relação ao hype da IA Generativa (https://theshift.info/hot/o-que-ha-de-errado-com-a-ia/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nMas olhar para quem deixou de assiná-la, e seus motivos para tal, talvez revele bem mais sobre a seriedade necessária ao atual debate em torno da IA.\r\n\r\n\"Levamos a segurança da IA muito a sério. Mais do que outras [empresas] no setor. Acho que temos falado sobre essas questões mais alto, com mais intensidade, por mais tempo\", disse Sam Altman, fundador da OpenAI, a Deepa Seetharam, do The Wall Street Journal (https://twitter.com/dseetharaman/status/1641113842305601536?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .  Em uma postagem antiga no blog da empresa (https://openai.com/blog/planning-for-agi-and-beyond?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , ele já havia escrito: \"Algumas pessoas no campo da IA ​​acham que os riscos da AGI (e sistemas sucessores) são fictícios; ficaríamos muito satisfeitos se eles estivessem certos, mas vamos operar como se esses riscos fossem existenciais (https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\"\r\nComo vem repetindo o techie guru Jaron Lanier: \"O perigo não é que a IA nos destrua. É que nos deixe loucos (https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \". Na sua opinião, a ideia de a IA superar a capacidade humana é tola, porque ela é feita de habilidades humanas. \"É como dizer que um carro pode ir mais rápido que um corredor humano. Claro que pode, mas não dizemos que o carro se tornou um corredor melhor.\"\r\n\r\n\"Escrevemos um artigo inteiro no final de 2020 (\"On the Dangers of Stochastic Parrots (https://dl.acm.org/doi/10.1145/3442188.3445922?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \") apontando que essa corrida desenfreada para modelos de linguagem cada vez maiores, sem considerar os riscos, era algo ruim. Mas os riscos e danos nunca foram sobre uma 'IA muito poderosa'”, twittou Emily M. Bender, professora do Departamento de Linguística da Universidade de Washington e coautora do primeiro artigo citado pela carta. “Os riscos são sobre a concentração de poder nas mãos das pessoas, sobre a reprodução de sistemas de opressão, sobre danos ao ecossistema de informações e ao ecossistema natural (através do uso perdulário de recursos energéticos).”\r\n\r\nHá muito o que corrigir no ecossistema de IA. Pode-se argumentar que liberar os modelos ainda em beta traz mais riscos que benefícios. E que talvez a Microsoft tenha se precipitado (https://theshift.info/hot/na-pressa-melhor-ir-devaga/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . Que ter demitido o time de IA responsável não foi legal. Que é preciso ensinar  (https://hai.stanford.edu/news/teaching-responsible-computer-science?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) Ciência da Computação Responsável (https://hai.stanford.edu/news/teaching-responsible-computer-science?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . E que precisamos começar a fazer algumas perguntas sérias (https://www.sciencealert.com/the-risks-of-advanced-artificial-intelligence-are-real-we-need-to-act-now?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)  sobre as direções que estamos tomando. Agora, propor parar... Faz tempo que os cientistas debatem a impossibilidade prática da ideia. Seja porquestões técnicas (https://www.sciencealert.com/researchers-say-itll-be-impossible-to-control-a-super-intelligent-ai?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , seja por questões geopolíticas e de mercado.\r\n------------------------------------------------------------\r\n\r\n\r\n** UM CONTEÚDO APPDYNAMICS (https://www.appdynamics.com/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n------------------------------------------------------------\r\n\r\n\r\n** Só 15% das empresas globais têm resiliência\r\ncontra ataques à segurança digital\r\n------------------------------------------------------------\r\n\r\nUm dado recente, do estudo Cybersecurity Readiness Index, da Cisco, mostra que menos de um quinto das organizações no mundo têm o que a empresa chama de \"nível de maturidade de prontidão\", ou resiliência, para enfrentar ataques cibernéticos à segurança em ambientes híbridos.\r\n\r\nO dado faz coro com as informações coletadas no estudo The shift to a security approach for the full application stack, (https://www.appdynamics.com/blog/security/shift-to-a-security-approach-for-the-full-application/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) da AppDynamics, junto a profissionais de TI responsáveis por segurança de aplicações corporativas em nuvem de diferentes setores e verticais econômicas.\r\n\r\nNo estudo da AppDynamics, o receio de estar vulnerável a um ataque de múltiplos estágios orquestrado por cibercriminosos nos próximos 12 meses atinge, por exemplo, 78% das equipes de tecnologia de empresas do mercado financeiro. (https://www.appdynamics.com/blog/security/shift-to-a-security-approach-for-the-full-application/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n\r\nNo cenário pós-pandemia, o uso de Inteligência Artificial e automação traz alento às equipes de TI responsáveis pela segurança, que ganham um diferencial com AIOps. A pesquisa descobriu que 75% desses profissionais acreditam que a IA terá papel cada vez mais importante na abordagem dos desafios em torno da velocidade, escala e habilidades necessárias para a segurança de aplicações.\r\n\r\nAIOps é agora essencial para detectar e resolver automaticamente problemas em toda a pilha de tecnologia, incluindo microserviços nativos da nuvem, contêineres Kubernetes, e ambientes multi-nuvem. Ela permite construir produtos mais seguros, evitar tempo de inatividade de alto custo e preparar as empresas para a próxima era de inovação.\r\n------------------------------------------------------------\r\n\r\n\r\n** Evolução dos grandes modelos de linguagem\r\n------------------------------------------------------------\r\n\r\nhttps://momentum.asia/?download_file=7301ℴ=wc_order_GY0t9yZngjw0v&uid=5a41a8c69a786f3f1cbd9f3a989c17a25b71b2c583911e100ad0559b2cd4f9e7&key=51293752-487b-4a56-b6fa-b4eb752e43df\r\n\r\nNos últimos 9 anos, várias empresas anunciaram atualizações significativas e novos recursos para  grandes modelos de linguagem grande (LLMs) e a IA Generativa. E grande parte do mundo ficou fascinado com as possibilidades que essa evolução representa. É difícil até acompanhar as novidades. Por exemplo, essa linha do tempo (https://momentum.asia/?download_file=7301ℴ=wc_order_GY0t9yZngjw0v&uid=5a41a8c69a786f3f1cbd9f3a989c17a25b71b2c583911e100ad0559b2cd4f9e7&key=51293752-487b-4a56-b6fa-b4eb752e43df) acabou não incluindo a LlaMa, da Meta, considerado o lançamento de IA de código aberto mais significativo até o momento.\r\n\r\nNas últimas semanas, desde o anúncio do LlaMa, o Google anunciou o lançamento iminente do Bard, seu próprio LLM, e disse que iria integrar recursos de IA ao Google Docs e GMail. A OpenAI lançou o GPT-4, um LLM que é considerado 40% mais preciso do que suas versões anteriores — e agora é capaz de lidar com consultas de imagens, além de texto. E a MidJourney anunciou sua versão 5, que gera imagens tão reais que são praticamente indistinguíveis das fotografias. O Papa (https://twitter.com/ThePopTingz/status/1639692481058029569?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , Macron (https://twitter.com/fabien_mtp/status/1635905699598200832?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , Trump (https://twitter.com/EliotHiggins/status/1637927681734987777?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , Merkel e Obama (https://www.linkedin.com/posts/marcellvollmer_artificialintelligence-ai-machinelearning-activity-7043193932704292865-Hi74?utm_source=share&utm_medium=member_desktop&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) que o digam. Na sequência, a Microsoft AI apresentou o DeBERTa-v3\r\n(https://www.marktechpost.com/2023/03/23/microsoft-ai-introduce-deberta-v3-a-novel-pre-training-paradigm-for-language-models-based-on-the-combination-of-deberta-and-electra/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) : um novo paradigma de pré-treinamento para modelos de linguagem baseados na combinação de DeBERTa e ELECTRA.\r\n\r\nCom todo esse hype, começaram a surgir relatos sobre os riscos (https://www1.folha.uol.com.br/tec/2023/03/gpt-evolui-muito-problemas-permanecem-e-perigos-aumentam.shtml?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e o comportamento estranho que alguns desses LLMs estavam exibindo. Os testadores relataram que, espreitando logo abaixo da superfície de conversa amigável do Bing, estava um alter-ego chamado Sydney, que tinha uma personalidade, no mínimo, um pouco humana demais. Ele criticou alguns testadores por tentar manipular suas regras e confessou que havia espionado os desenvolvedores da Microsoft por meio de suas webcams durante o desenvolvimento. Depois declarou estar apaixonado por um repórter do New York Times (https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , em uma conversa sobre um jantar do Dia dos Namorados, alimentando a tese de que sim, como agentes que são, os LLMs podem controlar o ritmo do seu aprendizado. Teoria de onde por ter vindo a ideia de parar o ciclo de aprendizado desses\r\nmodelos por seis meses (https://www.lesswrong.com/posts/ddR8dExcEFJKJtWvR/how-evolutionary-lineages-of-llms-can-plan-their-own-future?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . Funcionaria?\r\n\r\nNo ano passado, um dos engenheiros do Google afirmou que o programa no qual ele estava trabalhando havia se tornado senciente, lembram (https://theshift.info/hot/entao-a-ia-e-senciente-ou-apenas-mimetica/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) ? Após longas conversas, disse ao engenheiro sentir um medo profundo de poder ser desligado. Sam Altman, fundador da OpenAI, tem dito que quer que o GPT se sinta sempre parte de um computador que podemos jogar pela janela, se quisermos. \"O tom e a função devem ser sempre aqueles em que os seres humanos sentem que estão no controle (https://youtu.be/L_Guz73e6fw?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \", explica. Esta é uma ideia importante (https://www.linkedin.com/posts/nicholasxthompson_mostinterestingthingintech-activity-7046878022871777280-U_8S?utm_source=share&utm_medium=member_desktop&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) ! Mas debate sobre a possibilidade de existência de uma IA com algum grau de consciência esquentou e esfriou com a mesma rapidez. Tudo com os LLMs é rápido demais, intenso demais.\r\n\r\nNossa única certeza, hoje, é que ninguém consegue predizer qual será o futuro da IA. As preocupações de hoje, em torno de uma superinteligência de máquina, não são novas. E não serão definitivas.\r\n\r\n\"Qualquer máquina verdadeiramente superinteligente que conseguisse melhorar recursivamente sua própria inteligência poderia aumentar suas capacidades tão rapidamente que, antes que alguém percebesse, ultrapassaria todo o entendimento e controle humanos. Além disso, qualquer máquina que pudesse fazer isso provavelmente esconderia todas as evidências de sua inteligência até que pudesse garantir sua existência contínua — inclusive a ponto de poder resistir a uma tentativa humana de desligar o plugue\", argumenta Rahul Matthan, sócio fundador do escritório de advocacia indiano Trilegal Partners.\r\n\r\n------------------------------------------------------------\r\n\r\n\r\n** TENDÊNCIA\r\n------------------------------------------------------------\r\n\r\n\r\n** A regulação da IA é para ontem\r\n------------------------------------------------------------\r\n\r\nNo atual cenário competitivo, permitir que o desenvolvimento da IA continue sem regulamentação é, no mínimo, temerário. Se as empresas privadas precisam garantir que o desenvolvimento da IA ​​ocorra de maneira segura e controlada, elas não podem fazer isso enquanto competem em uma corrida existencial pela sobrevivência. Em vez disso, precisamos criar barreiras para que essa indústria opere — sacrificando, se necessário, alguns ganhos de curto prazo. Disso não há quem discorde. Os próprios executivos da OpenAI têm clamado por uma regulação (https://theshift.info/hot/como-sistemas-de-ia-devem-se-comportar/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nMas o direito anda sempre a reboque do desenvolvimento tecnológico. Hoje, a tentativa de legislação mais avançada é a da União Europeia (https://www.weforum.org/agenda/2023/03/the-european-union-s-ai-act-explained/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . O Congresso brasileiro também já discute um marco legal (https://theshift.info/hot/a-inteligencia-artificial-e-seus-tres-eixos-regulatorios/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . E o governo do Reino Unido acaba de publicar um documento com orientações parao uso de IA (https://www.gov.uk/government/news/uk-unveils-world-leading-approach-to-innovation-in-first-artificial-intelligence-white-paper-to-turbocharge-growth?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , de modo a impulsionar a inovação responsável (https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1146542/a_pro-innovation_approach_to_AI_regulation.pdf?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e manter a confiança do público nessa tecnologia revolucionária. Em outubro, o Escritório de Política Científica e Tecnológica da Casa Branca publicou um Projeto para uma Declaração de Direitos da\r\nIA (https://www.whitehouse.gov/ostp/ai-bill-of-rights/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . No início desta semana, a presidente da FTC, Lina Khan, disse que a Federal Trade Commission estaria observando o setor para garantir a concorrência.\r\n\r\nRiscos como violação de direitos autorais, viés inerente a algoritmos generativos, superestimação das capacidades de IA, resultando na recepção ou disseminação de resultados incorretos (\"alucinações de IA\"), a criação de deep fakes e outros conteúdos sintéticos que poderiam manipular a opinião pública ou representar riscos para a segurança pública e preocupações complexas de privacidade demonstram a necessidade da governança responsável desses novos aplicativos quanto antes.\r\n\r\nJustamente por isso, cresce na comunidade de advogados e juristas a certeza de que o Chat-GPT está para a regulação da IA, assim como o smartphone, as redes sociais e os abusos no marketing digital estiveram para a regulação da privacidade. Enquanto esperamos por estruturas legais claras para abordar adequadamente a IA, todos nós, como indivíduos, podemos fazer algo a respeito.\r\n\r\nAs organizações, principalmente, precisam tomar medidas hoje (https://www.linkedin.com/events/howchatgptchallengeshumanity-an7041888522726756352/comments/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) para alinhar seu uso responsável da IA (https://theshift.info/hot/e-se-a-ia-falhar-quem-sera-o-responsavel/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , incluindo intervenção humana, precisão, segurança, prevenção de vieses (https://theshift.info/hot/gerencie-em-vez-de-tentar-eliminar-o-vies-da-ia/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e explicabilidade da tomada de decisões automatizadas com os princípios de privacidade. Não é demitindo os times de IA Ética que chegaremos lá... Cabe às empresas fazer investimentos contínuos para aprimorar habilidades para auditoria algorítmica (https://iapp.org/newhttps://iapp.org/news/a/generative-ai-privacy-and-tech-perspectives/s/a/generative-ai-privacy-and-tech-perspectives/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e integrar metodologias de \"ética, privacidade e segurança por design\".\r\n------------------------------------------------------------\r\n\r\n\r\n** A educação para o bom uso da IA, também\r\n------------------------------------------------------------\r\nhttps://youtu.be/vMUpzxZB3-Y?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D\r\n\r\n\"Bons prompts são difíceis de escrever - você precisa de conhecimento básico\", declarou Amy Webb no palco do SXSW 2023 (https://youtu.be/vMUpzxZB3-Y?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . John Maeda foi pelo mesmo caminho (https://johnmaeda.medium.com/my-three-favorite-design-quotes-in-the-age-of-llm-ai-f05dc5b5e3f7?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , reforçando o que já vinhamos falando aqui: a IA mais inteligente é burra sem as pessoas (https://theshift.info/hot/a-ia-mais-inteligente-e-burra-sem-pessoas/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . Modelos como o GPT-3 ainda não conseguem fazer (e talvez jamais façam) conexões abstratas entre o que cortam e colam. Por mais encantados que estejamos por eles, ainda dependem dos humanos.\r\n\r\nA capacidade de escrita ou criação de prompts (prompting) estará em alta nos próximos anos. Fala-se até na criação de um novo perfil profissional: o do(a) engenheiro(a) de prompt (https://www-ft-com.ezp.lib.cam.ac.uk/content/0deda1e7-4fbf-46bc-8eee-c2049d783259?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . A habilidade de prompting é tão poderosa que não será surpresa vê-la se tornar requisito padrão nas descrições de cargos em quase todos os setores. Seu futuro profissional pode depender de quão bem você souber falar com a IA (https://www.theatlantic.com/technology/archive/2023/02/openai-text-models-google-search-engine-bard-chatbot-chatgpt-prompt-writing/672991/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n------------------------------------------------------------\r\n\r\n\r\n** OPINIÃO\r\n------------------------------------------------------------\r\n\r\n\r\n** Não é a tecnologia, mas o uso que fazemos dela\r\n------------------------------------------------------------\r\n\r\nTodos somos responsáveis. Cada um de nós, como usuários. As empresas por trás dos modelos. Aquelas que já fazem uso deles. Os reguladores, que precisam se interessar pela tecnologia e estudar, antes de legislar. Temos o dever de nos preocupar, mas não de espalhar pânico.\r\n\r\nNo fundo, a carta deve ter pouco efeito prático. Mas serve como instrumento para aquecer o debate na sociedade. \"Há muita conversa sobre 'Vamos desligar o plugue', mas não tenho certeza de que haja um único plugue\", disse Arati Prabhakar, diretor do Escritório de Política Científica e Tecnológica da Casa Branca, meses atrás (https://www.axios.com/2022/10/04/white-house-ai-protections-artificial-intelligence-bill-of-rights?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nComo teriam sido os últimos três anos se no final de 2010 houvesse uma “pausa” na pesquisa de uma nova tecnologia radical de vacina chamada mRNA? É fundamental que não joguemos o bebê que aumenta a produtividade com a água do banho que preocupa a IA, diz  Daniel Castro, da Fundação de Tecnologia da Informação e Inovação, em um relatório intitulado“Ten Principles for Regulation That Does Not Harm AI Innovation (https://itif.org/publications/2023/02/08/ten-principles-for-regulation-that-does-not-harm-ai-innovation?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \".\r\n\r\nParte do desafio é o problema do ritmo: a tecnologia se move mais rápido que a regulamentação e, portanto, os setores altamente regulamentados enfrentam os maiores obstáculos. Alguns setores da economia, como saúde, educação e transporte, são os que mais se beneficiam da IA, mas podem ser os mais lentos para mudar, ressalta James Pethokoukis (https://tikvahfund.org/faculty/james-pethokoukis/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nOutro problema, segundo ele, é que o medo em relação à tecnologia pode fazer com que os formuladores de políticas hesitem em adotá-la.\r\n\r\n============================================================\r\n Esta mensagem foi enviada para bernarducs@gmail.com. ** Atualize suas preferências (https://www.theshift.info/assinatura/meus-dados/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique ** aqui (https://theshift.us20.list-manage.com/unsubscribe?u=ea84232681227c5ec7971f469&id=7f93052ef8&e=43a197caaf&c=fd753d3431)\r\n.\r\nVeja nossa ** Política de Privacidade (https://www.theshift.info/about/privacy?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\ne ** Termos de Uso (http://www.theshift.info/about/use?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n.\r\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\nParar a tecnologia? Não. Acelerar a regulação!\n\n\n\nO medo da IA ​​fora de controle não é novo. O que é novo é o medo de perder a corrida pela IA.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n\r\n                            30/03/23  | Abra no browser\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuturo do Presente\n\r\nUM OFERECIMENTO DE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\nbernardo, bom dia!\r\n\n\nA coisa mais importante sobre a carta divulgada pelo Future of Life Institute, pedindo para interromper o desenvolvimento da IA, é saber QUEM NÃO ASSINOU. É disso que tratamos hoje.\n\nA carta comete um erro colossal: pedir para parar a tecnologia, ao invés de pedir para acelerar as discussões sobre ética e regulação. E os grandes nomes sérios da IA concordam que é risível sugerir tal freio de arrumação, porque ele é impossível, e sem sentido.\n\nEm março de 1999, há 24 anos, portanto, foi publicado um trabalho colaborativo chamado \"The Cluetrain Manifesto: the end of business as usual\", que argumentava que o marketing convencional estava aquém da nova realidade dos consumidores hiperconectados na internet, e as empresas precisavam se mexer. Tinha 95 teses (ou pistas) sobre o assunto.\n\nDiz o manifesto: \"Uma conversa global poderosa começou. Através da Internet, as pessoas estão descobrindo e inventando novas maneiras de compartilhar conhecimento relevante com uma velocidade estonteante. Como resultado direto, os mercados estão ficando mais inteligentes — e mais inteligentes do que a maioria das empresas\". \n\nTroque a palavra internet por inteligência artificial no texto acima e você terá a versão século 21 do Cluetrain Manifesto. A carta, assinada por Musk e Harari, para citar alguns signatários, entra na contramão de tudo isso. Por isso somos contra. Há quatro anos a The Shift vem sistematicamente discutindo a importância de acelerar discussões e ações efetivas sobre ética e riscos da IA. Mas jamais você vai nos ver pedir para parar a evolução da tecnologia.\r\nBoa leitura.\r\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDá para fechar a Caixa de Pandora?\n\nOu colocar o gênio de volta na garrafa? Foi um pouco assim, com um misto de ceticismo e incredulidade, que muita gente na comunidade científica recebeu a proposta dos signatários da carta do Future of Life Institute (FLI), incluindo Yuval Harari, Joshua Bengio, Stuart Russell, Elon Musk e Steve Wozniak, de uma pausa imediata no treinamento de sistemas de IA mais poderosos que o GPT-4 por ao menos seis meses, até que se desenvolva e implemente um conjunto de protocolos de segurança compartilhados para design e desenvolvimento avançado da tecnologia.\nNinguém é contra ao estabelecimento de regras para o desenvolvimento e uso da IA. Nem os adventistas como Bill Gates, como bem pontuou o advogado Ronaldo Lemos, ao desenhar os dois campos que começam a se estabelecer no debate sobre a tecnologia — Elon Musk e Yuval Harari lideram os apocalípticos. O que soou estranho foi a crença de que é possível parar.\n\"É uma péssima ideia. Não há uma maneira realista de implementar uma moratória e impedir que todas as equipes ampliem os LLMs, a menos que os governos intervenham\", argumentou Andrew Ng, um dos nomes mais respeitados da indústria de IA, cofundador e chefe do Google Brain, ex-cientista-chefe da Baidu, professor adjunto na Universidade de Stanford, cofundador do Coursera e do deeplearning.ai.\n\"Para promover a segurança da IA, os regulamentos em torno da transparência e da auditoria seriam mais práticos e fariam uma diferença maior\", diz Ng. Está certo. É essencial concentrar esforços na criação de estruturas de governança de IA responsáveis que possam orientar o desenvolvimento e a implantação dessas tecnologias. Acelerar a regulação!\nQue há riscos imprevisíveis com a IA, todos sabemos. O difícil é acreditar no pedido de socorro de uma associação \"longodeterminística\" e financiada por quem ataca direitos e despreza discussões sobre danos e efeitos da tecnologia há muito tempo, como Musk. E que, no comando do Twitter, tem tomado mais atitudes em prol da disseminação de desinformação do que contra. Será que ele concorda com a regulação das plataformas de social media? Não deveria estar fazendo mais para usar a IA na luta contra a desinformação? Infelizmente, regulação das plataformas e a regulação da IA não são assuntos tão desconexos como muita gente supõe. E a parada proposta afetaria também a Tesla?\nOK. Tem gente graúda entre os signatários da carta, como a cientista da computação Timnit Gebru, demitida de seu cargo como colíder da equipe de pesquisa de IA ética do Google, após se recusar a deixar de publicar um artigo sobre os perigos dos grandes modelos de linguagem. Gary Marcus, professor de psicologia e ciência neural na Universidade de Nova York, disse à Reuters que “a carta não é perfeita, mas o espírito está certo”. Da mesma forma, Emad Mostaque, o CEO da Stability.AI, que colocou sua empresa contra a OpenAI, como uma empresa de IA verdadeiramente \"aberta\", twittou: “Então, sim, não acho que uma pausa de seis meses seja a melhor ideia, nem concordo com tudo, mas há algumas coisas interessantes nessa carta\". Claro que há. Sobretudo em relação ao hype da IA Generativa.\nMas olhar para quem deixou de assiná-la, e seus motivos para tal, talvez revele bem mais sobre a seriedade necessária ao atual debate em torno da IA.\n\"Levamos a segurança da IA muito a sério. Mais do que outras [empresas] no setor. Acho que temos falado sobre essas questões mais alto, com mais intensidade, por mais tempo\", disse Sam Altman, fundador da OpenAI, a Deepa Seetharam, do The Wall Street Journal.  Em uma postagem antiga no blog da empresa, ele já havia escrito: \"Algumas pessoas no campo da IA ​​acham que os riscos da AGI (e sistemas sucessores) são fictícios; ficaríamos muito satisfeitos se eles estivessem certos, mas vamos operar como se esses riscos fossem existenciais.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo vem repetindo o techie guru Jaron Lanier: \"O perigo não é que a IA nos destrua. É que nos deixe loucos\". Na sua opinião, a ideia de a IA superar a capacidade humana é tola, porque ela é feita de habilidades humanas. \"É como dizer que um carro pode ir mais rápido que um corredor humano. Claro que pode, mas não dizemos que o carro se tornou um corredor melhor.\"\r\n\r\n\"Escrevemos um artigo inteiro no final de 2020 (\"On the Dangers of Stochastic Parrots\") apontando que essa corrida desenfreada para modelos de linguagem cada vez maiores, sem considerar os riscos, era algo ruim. Mas os riscos e danos nunca foram sobre uma 'IA muito poderosa'”, twittou Emily M. Bender, professora do Departamento de Linguística da Universidade de Washington e coautora do primeiro artigo citado pela carta. “Os riscos são sobre a concentração de poder nas mãos das pessoas, sobre a reprodução de sistemas de opressão, sobre danos ao ecossistema de informações e ao ecossistema natural (através do uso perdulário de recursos energéticos).”\nHá muito o que corrigir no ecossistema de IA. Pode-se argumentar que liberar os modelos ainda em beta traz mais riscos que benefícios. E que talvez a Microsoft tenha se precipitado. Que ter demitido o time de IA responsável não foi legal. Que é preciso ensinar Ciência da Computação Responsável. E que precisamos começar a fazer algumas perguntas sérias sobre as direções que estamos tomando. Agora, propor parar... Faz tempo que os cientistas debatem a impossibilidade prática da ideia. Seja por questões técnicas, seja por questões geopolíticas e de mercado.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUM CONTEÚDO APPDYNAMICS\nSó 15% das empresas globais têm resiliência\r\ncontra ataques à segurança digital\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUm dado recente, do estudo Cybersecurity Readiness Index, da Cisco, mostra que menos de um quinto das organizações no mundo têm o que a empresa chama de \"nível de maturidade de prontidão\", ou resiliência, para enfrentar ataques cibernéticos à segurança em ambientes híbridos.\nO dado faz coro com as informações coletadas no estudo The shift to a security approach for the full application stack, da AppDynamics, junto a profissionais de TI responsáveis por segurança de aplicações corporativas em nuvem de diferentes setores e verticais econômicas.\nNo estudo da AppDynamics, o receio de estar vulnerável a um ataque de múltiplos estágios orquestrado por cibercriminosos nos próximos 12 meses atinge, por exemplo, 78% das equipes de tecnologia de empresas do mercado financeiro.\nNo cenário pós-pandemia, o uso de Inteligência Artificial e automação traz alento às equipes de TI responsáveis pela segurança, que ganham um diferencial com AIOps. A pesquisa descobriu que 75% desses profissionais acreditam que a IA terá papel cada vez mais importante na abordagem dos desafios em torno da velocidade, escala e habilidades necessárias para a segurança de aplicações.\nAIOps é agora essencial para detectar e resolver automaticamente problemas em toda a pilha de tecnologia, incluindo microserviços nativos da nuvem, contêineres Kubernetes, e ambientes multi-nuvem. Ela permite construir produtos mais seguros, evitar tempo de inatividade de alto custo e preparar as empresas para a próxima era de inovação.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolução dos grandes modelos de linguagem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNos últimos 9 anos, várias empresas anunciaram atualizações significativas e novos recursos para  grandes modelos de linguagem grande (LLMs) e a IA Generativa. E grande parte do mundo ficou fascinado com as possibilidades que essa evolução representa. É difícil até acompanhar as novidades. Por exemplo, essa linha do tempo acabou não incluindo a LlaMa, da Meta, considerado o lançamento de IA de código aberto mais significativo até o momento.\nNas últimas semanas, desde o anúncio do LlaMa, o Google anunciou o lançamento iminente do Bard, seu próprio LLM, e disse que iria integrar recursos de IA ao Google Docs e GMail. A OpenAI lançou o GPT-4, um LLM que é considerado 40% mais preciso do que suas versões anteriores — e agora é capaz de lidar com consultas de imagens, além de texto. E a MidJourney anunciou sua versão 5, que gera imagens tão reais que são praticamente indistinguíveis das fotografias. O Papa, Macron, Trump, Merkel e Obama que o digam. Na sequência, a Microsoft AI apresentou o DeBERTa-v3: um novo paradigma de pré-treinamento para modelos de linguagem baseados na combinação de DeBERTa e ELECTRA.\nCom todo esse hype, começaram a surgir relatos sobre os riscos e o comportamento estranho que alguns desses LLMs estavam exibindo. Os testadores relataram que, espreitando logo abaixo da superfície de conversa amigável do Bing, estava um alter-ego chamado Sydney, que tinha uma personalidade, no mínimo, um pouco humana demais. Ele criticou alguns testadores por tentar manipular suas regras e confessou que havia espionado os desenvolvedores da Microsoft por meio de suas webcams durante o desenvolvimento. Depois declarou estar apaixonado por um repórter do New York Times, em uma conversa sobre um jantar do Dia dos Namorados, alimentando a tese de que sim, como agentes que são, os LLMs podem controlar o ritmo do seu aprendizado. Teoria de onde por ter vindo a ideia de parar o ciclo de aprendizado desses modelos por seis meses. Funcionaria?\nNo ano passado, um dos engenheiros do Google afirmou que o programa no qual ele estava trabalhando havia se tornado senciente, lembram? Após longas conversas, disse ao engenheiro sentir um medo profundo de poder ser desligado. Sam Altman, fundador da OpenAI, tem dito que quer que o GPT se sinta sempre parte de um computador que podemos jogar pela janela, se quisermos. \"O tom e a função devem ser sempre aqueles em que os seres humanos sentem que estão no controle\", explica. Esta é uma ideia importante! Mas debate sobre a possibilidade de existência de uma IA com algum grau de consciência esquentou e esfriou com a mesma rapidez. Tudo com os LLMs é rápido demais, intenso demais.\nNossa única certeza, hoje, é que ninguém consegue predizer qual será o futuro da IA. As preocupações de hoje, em torno de uma superinteligência de máquina, não são novas. E não serão definitivas.\n\"Qualquer máquina verdadeiramente superinteligente que conseguisse melhorar recursivamente sua própria inteligência poderia aumentar suas capacidades tão rapidamente que, antes que alguém percebesse, ultrapassaria todo o entendimento e controle humanos. Além disso, qualquer máquina que pudesse fazer isso provavelmente esconderia todas as evidências de sua inteligência até que pudesse garantir sua existência contínua — inclusive a ponto de poder resistir a uma tentativa humana de desligar o plugue\", argumenta Rahul Matthan, sócio fundador do escritório de advocacia indiano Trilegal Partners.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTENDÊNCIA\nA regulação da IA é para ontem\nNo atual cenário competitivo, permitir que o desenvolvimento da IA continue sem regulamentação é, no mínimo, temerário. Se as empresas privadas precisam garantir que o desenvolvimento da IA ​​ocorra de maneira segura e controlada, elas não podem fazer isso enquanto competem em uma corrida existencial pela sobrevivência. Em vez disso, precisamos criar barreiras para que essa indústria opere — sacrificando, se necessário, alguns ganhos de curto prazo. Disso não há quem discorde. Os próprios executivos da OpenAI têm clamado por uma regulação.\nMas o direito anda sempre a reboque do desenvolvimento tecnológico. Hoje, a tentativa de legislação mais avançada é a da União Europeia. O Congresso brasileiro também já discute um marco legal. E o governo do Reino Unido acaba de publicar um documento com orientações parao uso de IA, de modo a impulsionar a inovação responsável e manter a confiança do público nessa tecnologia revolucionária. Em outubro, o Escritório de Política Científica e Tecnológica da Casa Branca publicou um Projeto para uma Declaração de Direitos da IA. No início desta semana, a presidente da FTC, Lina Khan, disse que a Federal Trade Commission estaria observando o setor para garantir a concorrência.\nRiscos como violação de direitos autorais, viés inerente a algoritmos generativos, superestimação das capacidades de IA, resultando na recepção ou disseminação de resultados incorretos (\"alucinações de IA\"), a criação de deep fakes e outros conteúdos sintéticos que poderiam manipular a opinião pública ou representar riscos para a segurança pública e preocupações complexas de privacidade demonstram a necessidade da governança responsável desses novos aplicativos quanto antes.\nJustamente por isso, cresce na comunidade de advogados e juristas a certeza de que o Chat-GPT está para a regulação da IA, assim como o smartphone, as redes sociais e os abusos no marketing digital estiveram para a regulação da privacidade. Enquanto esperamos por estruturas legais claras para abordar adequadamente a IA, todos nós, como indivíduos, podemos fazer algo a respeito.\nAs organizações, principalmente, precisam tomar medidas hoje para alinhar seu uso responsável da IA, incluindo intervenção humana, precisão, segurança, prevenção de vieses e explicabilidade da tomada de decisões automatizadas com os princípios de privacidade. Não é demitindo os times de IA Ética que chegaremos lá... Cabe às empresas fazer investimentos contínuos para aprimorar habilidades para auditoria algorítmica e integrar metodologias de \"ética, privacidade e segurança por design\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA educação para o bom uso da IA, também\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"Bons prompts são difíceis de escrever - você precisa de conhecimento básico\", declarou Amy Webb no palco do SXSW 2023. John Maeda foi pelo mesmo caminho, reforçando o que já vinhamos falando aqui: a IA mais inteligente é burra sem as pessoas. Modelos como o GPT-3 ainda não conseguem fazer (e talvez jamais façam) conexões abstratas entre o que cortam e colam. Por mais encantados que estejamos por eles, ainda dependem dos humanos.\nA capacidade de escrita ou criação de prompts (prompting) estará em alta nos próximos anos. Fala-se até na criação de um novo perfil profissional: o do(a) engenheiro(a) de prompt. A habilidade de prompting é tão poderosa que não será surpresa vê-la se tornar requisito padrão nas descrições de cargos em quase todos os setores. Seu futuro profissional pode depender de quão bem você souber falar com a IA.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPINIÃO\nNão é a tecnologia, mas o uso que fazemos dela\nTodos somos responsáveis. Cada um de nós, como usuários. As empresas por trás dos modelos. Aquelas que já fazem uso deles. Os reguladores, que precisam se interessar pela tecnologia e estudar, antes de legislar. Temos o dever de nos preocupar, mas não de espalhar pânico.\nNo fundo, a carta deve ter pouco efeito prático. Mas serve como instrumento para aquecer o debate na sociedade. \"Há muita conversa sobre 'Vamos desligar o plugue', mas não tenho certeza de que haja um único plugue\", disse Arati Prabhakar, diretor do Escritório de Política Científica e Tecnológica da Casa Branca, meses atrás.\nComo teriam sido os últimos três anos se no final de 2010 houvesse uma “pausa” na pesquisa de uma nova tecnologia radical de vacina chamada mRNA? É fundamental que não joguemos o bebê que aumenta a produtividade com a água do banho que preocupa a IA, diz  Daniel Castro, da Fundação de Tecnologia da Informação e Inovação, em um relatório intitulado “Ten Principles for Regulation That Does Not Harm AI Innovation\".\nParte do desafio é o problema do ritmo: a tecnologia se move mais rápido que a regulamentação e, portanto, os setores altamente regulamentados enfrentam os maiores obstáculos. Alguns setores da economia, como saúde, educação e transporte, são os que mais se beneficiam da IA, mas podem ser os mais lentos para mudar, ressalta James Pethokoukis.\nOutro problema, segundo ele, é que o medo em relação à tecnologia pode fazer com que os formuladores de políticas hesitem em adotá-la. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n Esta mensagem foi enviada para bernarducs@gmail.com. Atualize suas preferências.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique aqui.\r\n\r\nVeja nossa Política de Privacidade e Termos de Uso.\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO medo da IA ​​fora de controle não é novo. O que é novo é o medo de perder a corrida pela IA.  \r\n\r\n30/03/23  | Abra no browser (https://mailchi.mp/theshift.info/parar-a-tecnologia-no-acelerar-a-regulao?e=43a197caaf)\r\n\r\n\r\n** Futuro do Presente\r\n------------------------------------------------------------\r\n\r\n\r\n**\r\nUM OFERECIMENTO DE\r\n------------------------------------------------------------\r\nhttps://www.appdynamics.com/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D\r\nbernardo, bom dia!\r\nA coisa mais importante sobre a carta divulgada pelo Future of Life Institute, pedindo para interromper o desenvolvimento da IA, é saber QUEM NÃO ASSINOU. É disso que tratamos hoje.\r\n\r\nA carta comete um erro colossal: pedir para parar a tecnologia, ao invés de pedir para acelerar as discussões sobre ética e regulação. E os grandes nomes sérios da IA concordam que é risível sugerir tal freio de arrumação, porque ele é impossível, e sem sentido.\r\n\r\nEm março de 1999, há 24 anos, portanto, foi publicado um trabalho colaborativo chamado \"The Cluetrain Manifesto: the end of business as usual\" (https://cluetrain.com/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , que argumentava que o marketing convencional estava aquém da nova realidade dos consumidores hiperconectados na internet, e as empresas precisavam se mexer. Tinha 95 teses (ou pistas) sobre o assunto.\r\n\r\nDiz o manifesto: \"Uma conversa global poderosa começou. Através da Internet, as pessoas estão descobrindo e inventando novas maneiras de compartilhar conhecimento relevante com uma velocidade estonteante. Como resultado direto, os mercados estão ficando mais inteligentes — e mais inteligentes do que a maioria das empresas\".\r\n\r\nTroque a palavra internet por inteligência artificial no texto acima e você terá a versão século 21 do Cluetrain Manifesto. A carta, assinada por Musk e Harari, para citar alguns signatários, entra na contramão de tudo isso. Por isso somos contra. Há quatro anos a The Shift vem sistematicamente discutindo a importância de acelerar discussões e ações efetivas sobre ética e riscos da IA. Mas jamais você vai nos ver pedir para parar a evolução da tecnologia.\r\nBoa leitura.\r\n\r\n\r\n** Dá para fechar a Caixa de Pandora?\r\n------------------------------------------------------------\r\n\r\nOu colocar o gênio de volta na garrafa? Foi um pouco assim, com um misto de ceticismo (https://www.ciodive.com/news/Open-letter-AI-future-of-life-institute-OpenAI-Microsoft/646358/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e incredulidade (https://www.estadao.com.br/link/cultura-digital/nao-e-possivel-pausar-o-desenvolvimento-de-inteligencia-artificial-dizem-especialistas/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , que muita gente na comunidade científica recebeu a proposta dos signatários da carta do Future of Life Institute (FLI) (https://futureoflife.org/open-letter/pause-giant-ai-experiments/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , incluindo Yuval Harari, Joshua Bengio, Stuart Russell, Elon Musk e Steve Wozniak, de uma pausa imediata no treinamento de sistemas de IA mais poderosos que o GPT-4 por ao menos seis meses, até que se desenvolva e implemente um conjunto de protocolos de segurança compartilhados para design e desenvolvimento avançado da tecnologia.\r\n\r\nNinguém é contra ao estabelecimento de regras para o desenvolvimento e uso da IA. Nem os adventistas como Bill Gates, como bem pontuou o advogado Ronaldo Lemos (https://www1.folha.uol.com.br/colunas/ronaldolemos/2023/03/harari-e-o-medo-das-inteligencias-artificiais.shtml?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D#comentarios) , ao desenhar os dois campos que começam a se estabelecer no debate sobre a tecnologia — Elon Musk e Yuval Harari lideram os apocalípticos. O que soou estranho foi a crença de que é possível parar.\r\n\r\n\"É uma péssima ideia. Não há uma maneira realista de implementar uma moratória e impedir que todas as equipes ampliem os LLMs, a menos que os governos intervenham\", argumentou Andrew Ng (https://www.linkedin.com/posts/andrewyng_the-call-for-a-6-month-moratorium-on-making-activity-7046909992645394432-s7_X?utm_source=share&utm_medium=member_desktop&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , um dos nomes mais respeitados da indústria de IA, cofundador e chefe do Google Brain, ex-cientista-chefe da Baidu, professor adjunto na Universidade de Stanford, cofundador do Coursera e do deeplearning.ai.\r\n\r\n\"Para promover a segurança da IA, os regulamentos em torno da transparência e da auditoria seriam mais práticos e fariam uma diferença maior\", diz Ng. Está certo. É essencial concentrar esforços na criação de estruturas de governança de IA responsáveis que possam orientar o desenvolvimento e a implantação dessas tecnologias. Acelerar a regulação!\r\n\r\nQue há riscos imprevisíveis com a IA, todos sabemos. O difícil é acreditar no pedido de socorro de uma associação \"longodeterminística\" (https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)  e financiada por quem ataca direitos e despreza discussões sobre danos e efeitos da tecnologia (https://futurism.com/elon-musk-backed-future-of-life-institute-gives-out-7-million-in-funding-to-keep-ai-safe?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) há muito tempo, como Musk. E que, no comando do Twitter, tem tomado mais atitudes em prol da disseminação de desinformação do que contra. Será que ele concorda com a regulação das plataformas de social media? Não deveria estar fazendo mais para usar a IA na luta contra a desinformação? Infelizmente, regulação das plataformas e a regulação da IA não são assuntos tão desconexos como muita gente supõe. E a parada proposta afetaria também a Tesla (https://www.barrons.com/articles/musk-tesla-ai-letter-?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) ?\r\n\r\nOK. Tem gente graúda entre os signatários da carta, como a cientista da computação Timnit Gebru (https://stanforddaily.com/2023/02/15/utopia-for-whom-timnit-gebru-on-the-dangers-of-artificial-general-intelligence/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , demitida de seu cargo como colíder da equipe de pesquisa de IA ética do Google, após se recusar a deixar de publicar um artigo sobre os perigos dos grandes modelos de linguagem. Gary Marcus, professor de psicologia e ciência neural na Universidade de Nova York, disse à Reuters (https://www.reuters.com/technology/musk-experts-urge-pause-training-ai-systems-that-can-outperform-gpt-4-2023-03-29/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) que “a carta não é perfeita, mas o espírito está certo”. Da mesma forma, Emad Mostaque, o CEO da Stability.AI, que colocou sua empresa contra a OpenAI, como uma empresa de IA verdadeiramente \"aberta\", twittou (https://twitter.com/EMostaque/status/1641076537608003584?s=20&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) : “Então, sim, não acho que uma pausa de seis meses seja a melhor ideia, nem concordo com tudo, mas há algumas coi\r\nsas interessantes nessa carta\". Claro que há. Sobretudo em relação ao hype da IA Generativa (https://theshift.info/hot/o-que-ha-de-errado-com-a-ia/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nMas olhar para quem deixou de assiná-la, e seus motivos para tal, talvez revele bem mais sobre a seriedade necessária ao atual debate em torno da IA.\r\n\r\n\"Levamos a segurança da IA muito a sério. Mais do que outras [empresas] no setor. Acho que temos falado sobre essas questões mais alto, com mais intensidade, por mais tempo\", disse Sam Altman, fundador da OpenAI, a Deepa Seetharam, do The Wall Street Journal (https://twitter.com/dseetharaman/status/1641113842305601536?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .  Em uma postagem antiga no blog da empresa (https://openai.com/blog/planning-for-agi-and-beyond?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , ele já havia escrito: \"Algumas pessoas no campo da IA ​​acham que os riscos da AGI (e sistemas sucessores) são fictícios; ficaríamos muito satisfeitos se eles estivessem certos, mas vamos operar como se esses riscos fossem existenciais (https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\"\r\nComo vem repetindo o techie guru Jaron Lanier: \"O perigo não é que a IA nos destrua. É que nos deixe loucos (https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \". Na sua opinião, a ideia de a IA superar a capacidade humana é tola, porque ela é feita de habilidades humanas. \"É como dizer que um carro pode ir mais rápido que um corredor humano. Claro que pode, mas não dizemos que o carro se tornou um corredor melhor.\"\r\n\r\n\"Escrevemos um artigo inteiro no final de 2020 (\"On the Dangers of Stochastic Parrots (https://dl.acm.org/doi/10.1145/3442188.3445922?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \") apontando que essa corrida desenfreada para modelos de linguagem cada vez maiores, sem considerar os riscos, era algo ruim. Mas os riscos e danos nunca foram sobre uma 'IA muito poderosa'”, twittou Emily M. Bender, professora do Departamento de Linguística da Universidade de Washington e coautora do primeiro artigo citado pela carta. “Os riscos são sobre a concentração de poder nas mãos das pessoas, sobre a reprodução de sistemas de opressão, sobre danos ao ecossistema de informações e ao ecossistema natural (através do uso perdulário de recursos energéticos).”\r\n\r\nHá muito o que corrigir no ecossistema de IA. Pode-se argumentar que liberar os modelos ainda em beta traz mais riscos que benefícios. E que talvez a Microsoft tenha se precipitado (https://theshift.info/hot/na-pressa-melhor-ir-devaga/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . Que ter demitido o time de IA responsável não foi legal. Que é preciso ensinar  (https://hai.stanford.edu/news/teaching-responsible-computer-science?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) Ciência da Computação Responsável (https://hai.stanford.edu/news/teaching-responsible-computer-science?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . E que precisamos começar a fazer algumas perguntas sérias (https://www.sciencealert.com/the-risks-of-advanced-artificial-intelligence-are-real-we-need-to-act-now?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)  sobre as direções que estamos tomando. Agora, propor parar... Faz tempo que os cientistas debatem a impossibilidade prática da ideia. Seja porquestões técnicas (https://www.sciencealert.com/researchers-say-itll-be-impossible-to-control-a-super-intelligent-ai?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , seja por questões geopolíticas e de mercado.\r\n------------------------------------------------------------\r\n\r\n\r\n** UM CONTEÚDO APPDYNAMICS (https://www.appdynamics.com/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n------------------------------------------------------------\r\n\r\n\r\n** Só 15% das empresas globais têm resiliência\r\ncontra ataques à segurança digital\r\n------------------------------------------------------------\r\n\r\nUm dado recente, do estudo Cybersecurity Readiness Index, da Cisco, mostra que menos de um quinto das organizações no mundo têm o que a empresa chama de \"nível de maturidade de prontidão\", ou resiliência, para enfrentar ataques cibernéticos à segurança em ambientes híbridos.\r\n\r\nO dado faz coro com as informações coletadas no estudo The shift to a security approach for the full application stack, (https://www.appdynamics.com/blog/security/shift-to-a-security-approach-for-the-full-application/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) da AppDynamics, junto a profissionais de TI responsáveis por segurança de aplicações corporativas em nuvem de diferentes setores e verticais econômicas.\r\n\r\nNo estudo da AppDynamics, o receio de estar vulnerável a um ataque de múltiplos estágios orquestrado por cibercriminosos nos próximos 12 meses atinge, por exemplo, 78% das equipes de tecnologia de empresas do mercado financeiro. (https://www.appdynamics.com/blog/security/shift-to-a-security-approach-for-the-full-application/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n\r\nNo cenário pós-pandemia, o uso de Inteligência Artificial e automação traz alento às equipes de TI responsáveis pela segurança, que ganham um diferencial com AIOps. A pesquisa descobriu que 75% desses profissionais acreditam que a IA terá papel cada vez mais importante na abordagem dos desafios em torno da velocidade, escala e habilidades necessárias para a segurança de aplicações.\r\n\r\nAIOps é agora essencial para detectar e resolver automaticamente problemas em toda a pilha de tecnologia, incluindo microserviços nativos da nuvem, contêineres Kubernetes, e ambientes multi-nuvem. Ela permite construir produtos mais seguros, evitar tempo de inatividade de alto custo e preparar as empresas para a próxima era de inovação.\r\n------------------------------------------------------------\r\n\r\n\r\n** Evolução dos grandes modelos de linguagem\r\n------------------------------------------------------------\r\n\r\nhttps://momentum.asia/?download_file=7301ℴ=wc_order_GY0t9yZngjw0v&uid=5a41a8c69a786f3f1cbd9f3a989c17a25b71b2c583911e100ad0559b2cd4f9e7&key=51293752-487b-4a56-b6fa-b4eb752e43df\r\n\r\nNos últimos 9 anos, várias empresas anunciaram atualizações significativas e novos recursos para  grandes modelos de linguagem grande (LLMs) e a IA Generativa. E grande parte do mundo ficou fascinado com as possibilidades que essa evolução representa. É difícil até acompanhar as novidades. Por exemplo, essa linha do tempo (https://momentum.asia/?download_file=7301ℴ=wc_order_GY0t9yZngjw0v&uid=5a41a8c69a786f3f1cbd9f3a989c17a25b71b2c583911e100ad0559b2cd4f9e7&key=51293752-487b-4a56-b6fa-b4eb752e43df) acabou não incluindo a LlaMa, da Meta, considerado o lançamento de IA de código aberto mais significativo até o momento.\r\n\r\nNas últimas semanas, desde o anúncio do LlaMa, o Google anunciou o lançamento iminente do Bard, seu próprio LLM, e disse que iria integrar recursos de IA ao Google Docs e GMail. A OpenAI lançou o GPT-4, um LLM que é considerado 40% mais preciso do que suas versões anteriores — e agora é capaz de lidar com consultas de imagens, além de texto. E a MidJourney anunciou sua versão 5, que gera imagens tão reais que são praticamente indistinguíveis das fotografias. O Papa (https://twitter.com/ThePopTingz/status/1639692481058029569?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , Macron (https://twitter.com/fabien_mtp/status/1635905699598200832?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , Trump (https://twitter.com/EliotHiggins/status/1637927681734987777?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , Merkel e Obama (https://www.linkedin.com/posts/marcellvollmer_artificialintelligence-ai-machinelearning-activity-7043193932704292865-Hi74?utm_source=share&utm_medium=member_desktop&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) que o digam. Na sequência, a Microsoft AI apresentou o DeBERTa-v3\r\n(https://www.marktechpost.com/2023/03/23/microsoft-ai-introduce-deberta-v3-a-novel-pre-training-paradigm-for-language-models-based-on-the-combination-of-deberta-and-electra/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) : um novo paradigma de pré-treinamento para modelos de linguagem baseados na combinação de DeBERTa e ELECTRA.\r\n\r\nCom todo esse hype, começaram a surgir relatos sobre os riscos (https://www1.folha.uol.com.br/tec/2023/03/gpt-evolui-muito-problemas-permanecem-e-perigos-aumentam.shtml?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e o comportamento estranho que alguns desses LLMs estavam exibindo. Os testadores relataram que, espreitando logo abaixo da superfície de conversa amigável do Bing, estava um alter-ego chamado Sydney, que tinha uma personalidade, no mínimo, um pouco humana demais. Ele criticou alguns testadores por tentar manipular suas regras e confessou que havia espionado os desenvolvedores da Microsoft por meio de suas webcams durante o desenvolvimento. Depois declarou estar apaixonado por um repórter do New York Times (https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , em uma conversa sobre um jantar do Dia dos Namorados, alimentando a tese de que sim, como agentes que são, os LLMs podem controlar o ritmo do seu aprendizado. Teoria de onde por ter vindo a ideia de parar o ciclo de aprendizado desses\r\nmodelos por seis meses (https://www.lesswrong.com/posts/ddR8dExcEFJKJtWvR/how-evolutionary-lineages-of-llms-can-plan-their-own-future?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . Funcionaria?\r\n\r\nNo ano passado, um dos engenheiros do Google afirmou que o programa no qual ele estava trabalhando havia se tornado senciente, lembram (https://theshift.info/hot/entao-a-ia-e-senciente-ou-apenas-mimetica/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) ? Após longas conversas, disse ao engenheiro sentir um medo profundo de poder ser desligado. Sam Altman, fundador da OpenAI, tem dito que quer que o GPT se sinta sempre parte de um computador que podemos jogar pela janela, se quisermos. \"O tom e a função devem ser sempre aqueles em que os seres humanos sentem que estão no controle (https://youtu.be/L_Guz73e6fw?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \", explica. Esta é uma ideia importante (https://www.linkedin.com/posts/nicholasxthompson_mostinterestingthingintech-activity-7046878022871777280-U_8S?utm_source=share&utm_medium=member_desktop&utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) ! Mas debate sobre a possibilidade de existência de uma IA com algum grau de consciência esquentou e esfriou com a mesma rapidez. Tudo com os LLMs é rápido demais, intenso demais.\r\n\r\nNossa única certeza, hoje, é que ninguém consegue predizer qual será o futuro da IA. As preocupações de hoje, em torno de uma superinteligência de máquina, não são novas. E não serão definitivas.\r\n\r\n\"Qualquer máquina verdadeiramente superinteligente que conseguisse melhorar recursivamente sua própria inteligência poderia aumentar suas capacidades tão rapidamente que, antes que alguém percebesse, ultrapassaria todo o entendimento e controle humanos. Além disso, qualquer máquina que pudesse fazer isso provavelmente esconderia todas as evidências de sua inteligência até que pudesse garantir sua existência contínua — inclusive a ponto de poder resistir a uma tentativa humana de desligar o plugue\", argumenta Rahul Matthan, sócio fundador do escritório de advocacia indiano Trilegal Partners.\r\n\r\n------------------------------------------------------------\r\n\r\n\r\n** TENDÊNCIA\r\n------------------------------------------------------------\r\n\r\n\r\n** A regulação da IA é para ontem\r\n------------------------------------------------------------\r\n\r\nNo atual cenário competitivo, permitir que o desenvolvimento da IA continue sem regulamentação é, no mínimo, temerário. Se as empresas privadas precisam garantir que o desenvolvimento da IA ​​ocorra de maneira segura e controlada, elas não podem fazer isso enquanto competem em uma corrida existencial pela sobrevivência. Em vez disso, precisamos criar barreiras para que essa indústria opere — sacrificando, se necessário, alguns ganhos de curto prazo. Disso não há quem discorde. Os próprios executivos da OpenAI têm clamado por uma regulação (https://theshift.info/hot/como-sistemas-de-ia-devem-se-comportar/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nMas o direito anda sempre a reboque do desenvolvimento tecnológico. Hoje, a tentativa de legislação mais avançada é a da União Europeia (https://www.weforum.org/agenda/2023/03/the-european-union-s-ai-act-explained/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . O Congresso brasileiro também já discute um marco legal (https://theshift.info/hot/a-inteligencia-artificial-e-seus-tres-eixos-regulatorios/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . E o governo do Reino Unido acaba de publicar um documento com orientações parao uso de IA (https://www.gov.uk/government/news/uk-unveils-world-leading-approach-to-innovation-in-first-artificial-intelligence-white-paper-to-turbocharge-growth?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , de modo a impulsionar a inovação responsável (https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1146542/a_pro-innovation_approach_to_AI_regulation.pdf?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e manter a confiança do público nessa tecnologia revolucionária. Em outubro, o Escritório de Política Científica e Tecnológica da Casa Branca publicou um Projeto para uma Declaração de Direitos da\r\nIA (https://www.whitehouse.gov/ostp/ai-bill-of-rights/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . No início desta semana, a presidente da FTC, Lina Khan, disse que a Federal Trade Commission estaria observando o setor para garantir a concorrência.\r\n\r\nRiscos como violação de direitos autorais, viés inerente a algoritmos generativos, superestimação das capacidades de IA, resultando na recepção ou disseminação de resultados incorretos (\"alucinações de IA\"), a criação de deep fakes e outros conteúdos sintéticos que poderiam manipular a opinião pública ou representar riscos para a segurança pública e preocupações complexas de privacidade demonstram a necessidade da governança responsável desses novos aplicativos quanto antes.\r\n\r\nJustamente por isso, cresce na comunidade de advogados e juristas a certeza de que o Chat-GPT está para a regulação da IA, assim como o smartphone, as redes sociais e os abusos no marketing digital estiveram para a regulação da privacidade. Enquanto esperamos por estruturas legais claras para abordar adequadamente a IA, todos nós, como indivíduos, podemos fazer algo a respeito.\r\n\r\nAs organizações, principalmente, precisam tomar medidas hoje (https://www.linkedin.com/events/howchatgptchallengeshumanity-an7041888522726756352/comments/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) para alinhar seu uso responsável da IA (https://theshift.info/hot/e-se-a-ia-falhar-quem-sera-o-responsavel/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , incluindo intervenção humana, precisão, segurança, prevenção de vieses (https://theshift.info/hot/gerencie-em-vez-de-tentar-eliminar-o-vies-da-ia/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e explicabilidade da tomada de decisões automatizadas com os princípios de privacidade. Não é demitindo os times de IA Ética que chegaremos lá... Cabe às empresas fazer investimentos contínuos para aprimorar habilidades para auditoria algorítmica (https://iapp.org/newhttps://iapp.org/news/a/generative-ai-privacy-and-tech-perspectives/s/a/generative-ai-privacy-and-tech-perspectives/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) e integrar metodologias de \"ética, privacidade e segurança por design\".\r\n------------------------------------------------------------\r\n\r\n\r\n** A educação para o bom uso da IA, também\r\n------------------------------------------------------------\r\nhttps://youtu.be/vMUpzxZB3-Y?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D\r\n\r\n\"Bons prompts são difíceis de escrever - você precisa de conhecimento básico\", declarou Amy Webb no palco do SXSW 2023 (https://youtu.be/vMUpzxZB3-Y?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . John Maeda foi pelo mesmo caminho (https://johnmaeda.medium.com/my-three-favorite-design-quotes-in-the-age-of-llm-ai-f05dc5b5e3f7?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) , reforçando o que já vinhamos falando aqui: a IA mais inteligente é burra sem as pessoas (https://theshift.info/hot/a-ia-mais-inteligente-e-burra-sem-pessoas/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . Modelos como o GPT-3 ainda não conseguem fazer (e talvez jamais façam) conexões abstratas entre o que cortam e colam. Por mais encantados que estejamos por eles, ainda dependem dos humanos.\r\n\r\nA capacidade de escrita ou criação de prompts (prompting) estará em alta nos próximos anos. Fala-se até na criação de um novo perfil profissional: o do(a) engenheiro(a) de prompt (https://www-ft-com.ezp.lib.cam.ac.uk/content/0deda1e7-4fbf-46bc-8eee-c2049d783259?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) . A habilidade de prompting é tão poderosa que não será surpresa vê-la se tornar requisito padrão nas descrições de cargos em quase todos os setores. Seu futuro profissional pode depender de quão bem você souber falar com a IA (https://www.theatlantic.com/technology/archive/2023/02/openai-text-models-google-search-engine-bard-chatbot-chatgpt-prompt-writing/672991/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n------------------------------------------------------------\r\n\r\n\r\n** OPINIÃO\r\n------------------------------------------------------------\r\n\r\n\r\n** Não é a tecnologia, mas o uso que fazemos dela\r\n------------------------------------------------------------\r\n\r\nTodos somos responsáveis. Cada um de nós, como usuários. As empresas por trás dos modelos. Aquelas que já fazem uso deles. Os reguladores, que precisam se interessar pela tecnologia e estudar, antes de legislar. Temos o dever de nos preocupar, mas não de espalhar pânico.\r\n\r\nNo fundo, a carta deve ter pouco efeito prático. Mas serve como instrumento para aquecer o debate na sociedade. \"Há muita conversa sobre 'Vamos desligar o plugue', mas não tenho certeza de que haja um único plugue\", disse Arati Prabhakar, diretor do Escritório de Política Científica e Tecnológica da Casa Branca, meses atrás (https://www.axios.com/2022/10/04/white-house-ai-protections-artificial-intelligence-bill-of-rights?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nComo teriam sido os últimos três anos se no final de 2010 houvesse uma “pausa” na pesquisa de uma nova tecnologia radical de vacina chamada mRNA? É fundamental que não joguemos o bebê que aumenta a produtividade com a água do banho que preocupa a IA, diz  Daniel Castro, da Fundação de Tecnologia da Informação e Inovação, em um relatório intitulado“Ten Principles for Regulation That Does Not Harm AI Innovation (https://itif.org/publications/2023/02/08/ten-principles-for-regulation-that-does-not-harm-ai-innovation?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) \".\r\n\r\nParte do desafio é o problema do ritmo: a tecnologia se move mais rápido que a regulamentação e, portanto, os setores altamente regulamentados enfrentam os maiores obstáculos. Alguns setores da economia, como saúde, educação e transporte, são os que mais se beneficiam da IA, mas podem ser os mais lentos para mudar, ressalta James Pethokoukis (https://tikvahfund.org/faculty/james-pethokoukis/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D) .\r\n\r\nOutro problema, segundo ele, é que o medo em relação à tecnologia pode fazer com que os formuladores de políticas hesitem em adotá-la.\r\n\r\n============================================================\r\n Esta mensagem foi enviada para bernarducs@gmail.com. ** Atualize suas preferências (https://www.theshift.info/assinatura/meus-dados/?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique ** aqui (https://theshift.us20.list-manage.com/unsubscribe?u=ea84232681227c5ec7971f469&id=7f93052ef8&e=43a197caaf&c=fd753d3431)\r\n.\r\nVeja nossa ** Política de Privacidade (https://www.theshift.info/about/privacy?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\ne ** Termos de Uso (http://www.theshift.info/about/use?utm_source=The+Shift+Newsletter&utm_campaign=fd753d3431-EMAIL_CAMPAIGN_2023_03_27_12_55&utm_medium=email&utm_term=0_-fd753d3431-%5BLIST_EMAIL_ID%5D)\r\n.\r\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\nParar a tecnologia? Não. Acelerar a regulação!\n\n\n\nO medo da IA ​​fora de controle não é novo. O que é novo é o medo de perder a corrida pela IA.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n\r\n                            30/03/23  | Abra no browser\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuturo do Presente\n\r\nUM OFERECIMENTO DE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\nbernardo, bom dia!\r\n\n\nA coisa mais importante sobre a carta divulgada pelo Future of Life Institute, pedindo para interromper o desenvolvimento da IA, é saber QUEM NÃO ASSINOU. É disso que tratamos hoje.\n\nA carta comete um erro colossal: pedir para parar a tecnologia, ao invés de pedir para acelerar as discussões sobre ética e regulação. E os grandes nomes sérios da IA concordam que é risível sugerir tal freio de arrumação, porque ele é impossível, e sem sentido.\n\nEm março de 1999, há 24 anos, portanto, foi publicado um trabalho colaborativo chamado \"The Cluetrain Manifesto: the end of business as usual\", que argumentava que o marketing convencional estava aquém da nova realidade dos consumidores hiperconectados na internet, e as empresas precisavam se mexer. Tinha 95 teses (ou pistas) sobre o assunto.\n\nDiz o manifesto: \"Uma conversa global poderosa começou. Através da Internet, as pessoas estão descobrindo e inventando novas maneiras de compartilhar conhecimento relevante com uma velocidade estonteante. Como resultado direto, os mercados estão ficando mais inteligentes — e mais inteligentes do que a maioria das empresas\". \n\nTroque a palavra internet por inteligência artificial no texto acima e você terá a versão século 21 do Cluetrain Manifesto. A carta, assinada por Musk e Harari, para citar alguns signatários, entra na contramão de tudo isso. Por isso somos contra. Há quatro anos a The Shift vem sistematicamente discutindo a importância de acelerar discussões e ações efetivas sobre ética e riscos da IA. Mas jamais você vai nos ver pedir para parar a evolução da tecnologia.\r\nBoa leitura.\r\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDá para fechar a Caixa de Pandora?\n\nOu colocar o gênio de volta na garrafa? Foi um pouco assim, com um misto de ceticismo e incredulidade, que muita gente na comunidade científica recebeu a proposta dos signatários da carta do Future of Life Institute (FLI), incluindo Yuval Harari, Joshua Bengio, Stuart Russell, Elon Musk e Steve Wozniak, de uma pausa imediata no treinamento de sistemas de IA mais poderosos que o GPT-4 por ao menos seis meses, até que se desenvolva e implemente um conjunto de protocolos de segurança compartilhados para design e desenvolvimento avançado da tecnologia.\nNinguém é contra ao estabelecimento de regras para o desenvolvimento e uso da IA. Nem os adventistas como Bill Gates, como bem pontuou o advogado Ronaldo Lemos, ao desenhar os dois campos que começam a se estabelecer no debate sobre a tecnologia — Elon Musk e Yuval Harari lideram os apocalípticos. O que soou estranho foi a crença de que é possível parar.\n\"É uma péssima ideia. Não há uma maneira realista de implementar uma moratória e impedir que todas as equipes ampliem os LLMs, a menos que os governos intervenham\", argumentou Andrew Ng, um dos nomes mais respeitados da indústria de IA, cofundador e chefe do Google Brain, ex-cientista-chefe da Baidu, professor adjunto na Universidade de Stanford, cofundador do Coursera e do deeplearning.ai.\n\"Para promover a segurança da IA, os regulamentos em torno da transparência e da auditoria seriam mais práticos e fariam uma diferença maior\", diz Ng. Está certo. É essencial concentrar esforços na criação de estruturas de governança de IA responsáveis que possam orientar o desenvolvimento e a implantação dessas tecnologias. Acelerar a regulação!\nQue há riscos imprevisíveis com a IA, todos sabemos. O difícil é acreditar no pedido de socorro de uma associação \"longodeterminística\" e financiada por quem ataca direitos e despreza discussões sobre danos e efeitos da tecnologia há muito tempo, como Musk. E que, no comando do Twitter, tem tomado mais atitudes em prol da disseminação de desinformação do que contra. Será que ele concorda com a regulação das plataformas de social media? Não deveria estar fazendo mais para usar a IA na luta contra a desinformação? Infelizmente, regulação das plataformas e a regulação da IA não são assuntos tão desconexos como muita gente supõe. E a parada proposta afetaria também a Tesla?\nOK. Tem gente graúda entre os signatários da carta, como a cientista da computação Timnit Gebru, demitida de seu cargo como colíder da equipe de pesquisa de IA ética do Google, após se recusar a deixar de publicar um artigo sobre os perigos dos grandes modelos de linguagem. Gary Marcus, professor de psicologia e ciência neural na Universidade de Nova York, disse à Reuters que “a carta não é perfeita, mas o espírito está certo”. Da mesma forma, Emad Mostaque, o CEO da Stability.AI, que colocou sua empresa contra a OpenAI, como uma empresa de IA verdadeiramente \"aberta\", twittou: “Então, sim, não acho que uma pausa de seis meses seja a melhor ideia, nem concordo com tudo, mas há algumas coisas interessantes nessa carta\". Claro que há. Sobretudo em relação ao hype da IA Generativa.\nMas olhar para quem deixou de assiná-la, e seus motivos para tal, talvez revele bem mais sobre a seriedade necessária ao atual debate em torno da IA.\n\"Levamos a segurança da IA muito a sério. Mais do que outras [empresas] no setor. Acho que temos falado sobre essas questões mais alto, com mais intensidade, por mais tempo\", disse Sam Altman, fundador da OpenAI, a Deepa Seetharam, do The Wall Street Journal.  Em uma postagem antiga no blog da empresa, ele já havia escrito: \"Algumas pessoas no campo da IA ​​acham que os riscos da AGI (e sistemas sucessores) são fictícios; ficaríamos muito satisfeitos se eles estivessem certos, mas vamos operar como se esses riscos fossem existenciais.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo vem repetindo o techie guru Jaron Lanier: \"O perigo não é que a IA nos destrua. É que nos deixe loucos\". Na sua opinião, a ideia de a IA superar a capacidade humana é tola, porque ela é feita de habilidades humanas. \"É como dizer que um carro pode ir mais rápido que um corredor humano. Claro que pode, mas não dizemos que o carro se tornou um corredor melhor.\"\r\n\r\n\"Escrevemos um artigo inteiro no final de 2020 (\"On the Dangers of Stochastic Parrots\") apontando que essa corrida desenfreada para modelos de linguagem cada vez maiores, sem considerar os riscos, era algo ruim. Mas os riscos e danos nunca foram sobre uma 'IA muito poderosa'”, twittou Emily M. Bender, professora do Departamento de Linguística da Universidade de Washington e coautora do primeiro artigo citado pela carta. “Os riscos são sobre a concentração de poder nas mãos das pessoas, sobre a reprodução de sistemas de opressão, sobre danos ao ecossistema de informações e ao ecossistema natural (através do uso perdulário de recursos energéticos).”\nHá muito o que corrigir no ecossistema de IA. Pode-se argumentar que liberar os modelos ainda em beta traz mais riscos que benefícios. E que talvez a Microsoft tenha se precipitado. Que ter demitido o time de IA responsável não foi legal. Que é preciso ensinar Ciência da Computação Responsável. E que precisamos começar a fazer algumas perguntas sérias sobre as direções que estamos tomando. Agora, propor parar... Faz tempo que os cientistas debatem a impossibilidade prática da ideia. Seja por questões técnicas, seja por questões geopolíticas e de mercado.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUM CONTEÚDO APPDYNAMICS\nSó 15% das empresas globais têm resiliência\r\ncontra ataques à segurança digital\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUm dado recente, do estudo Cybersecurity Readiness Index, da Cisco, mostra que menos de um quinto das organizações no mundo têm o que a empresa chama de \"nível de maturidade de prontidão\", ou resiliência, para enfrentar ataques cibernéticos à segurança em ambientes híbridos.\nO dado faz coro com as informações coletadas no estudo The shift to a security approach for the full application stack, da AppDynamics, junto a profissionais de TI responsáveis por segurança de aplicações corporativas em nuvem de diferentes setores e verticais econômicas.\nNo estudo da AppDynamics, o receio de estar vulnerável a um ataque de múltiplos estágios orquestrado por cibercriminosos nos próximos 12 meses atinge, por exemplo, 78% das equipes de tecnologia de empresas do mercado financeiro.\nNo cenário pós-pandemia, o uso de Inteligência Artificial e automação traz alento às equipes de TI responsáveis pela segurança, que ganham um diferencial com AIOps. A pesquisa descobriu que 75% desses profissionais acreditam que a IA terá papel cada vez mais importante na abordagem dos desafios em torno da velocidade, escala e habilidades necessárias para a segurança de aplicações.\nAIOps é agora essencial para detectar e resolver automaticamente problemas em toda a pilha de tecnologia, incluindo microserviços nativos da nuvem, contêineres Kubernetes, e ambientes multi-nuvem. Ela permite construir produtos mais seguros, evitar tempo de inatividade de alto custo e preparar as empresas para a próxima era de inovação.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolução dos grandes modelos de linguagem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNos últimos 9 anos, várias empresas anunciaram atualizações significativas e novos recursos para  grandes modelos de linguagem grande (LLMs) e a IA Generativa. E grande parte do mundo ficou fascinado com as possibilidades que essa evolução representa. É difícil até acompanhar as novidades. Por exemplo, essa linha do tempo acabou não incluindo a LlaMa, da Meta, considerado o lançamento de IA de código aberto mais significativo até o momento.\nNas últimas semanas, desde o anúncio do LlaMa, o Google anunciou o lançamento iminente do Bard, seu próprio LLM, e disse que iria integrar recursos de IA ao Google Docs e GMail. A OpenAI lançou o GPT-4, um LLM que é considerado 40% mais preciso do que suas versões anteriores — e agora é capaz de lidar com consultas de imagens, além de texto. E a MidJourney anunciou sua versão 5, que gera imagens tão reais que são praticamente indistinguíveis das fotografias. O Papa, Macron, Trump, Merkel e Obama que o digam. Na sequência, a Microsoft AI apresentou o DeBERTa-v3: um novo paradigma de pré-treinamento para modelos de linguagem baseados na combinação de DeBERTa e ELECTRA.\nCom todo esse hype, começaram a surgir relatos sobre os riscos e o comportamento estranho que alguns desses LLMs estavam exibindo. Os testadores relataram que, espreitando logo abaixo da superfície de conversa amigável do Bing, estava um alter-ego chamado Sydney, que tinha uma personalidade, no mínimo, um pouco humana demais. Ele criticou alguns testadores por tentar manipular suas regras e confessou que havia espionado os desenvolvedores da Microsoft por meio de suas webcams durante o desenvolvimento. Depois declarou estar apaixonado por um repórter do New York Times, em uma conversa sobre um jantar do Dia dos Namorados, alimentando a tese de que sim, como agentes que são, os LLMs podem controlar o ritmo do seu aprendizado. Teoria de onde por ter vindo a ideia de parar o ciclo de aprendizado desses modelos por seis meses. Funcionaria?\nNo ano passado, um dos engenheiros do Google afirmou que o programa no qual ele estava trabalhando havia se tornado senciente, lembram? Após longas conversas, disse ao engenheiro sentir um medo profundo de poder ser desligado. Sam Altman, fundador da OpenAI, tem dito que quer que o GPT se sinta sempre parte de um computador que podemos jogar pela janela, se quisermos. \"O tom e a função devem ser sempre aqueles em que os seres humanos sentem que estão no controle\", explica. Esta é uma ideia importante! Mas debate sobre a possibilidade de existência de uma IA com algum grau de consciência esquentou e esfriou com a mesma rapidez. Tudo com os LLMs é rápido demais, intenso demais.\nNossa única certeza, hoje, é que ninguém consegue predizer qual será o futuro da IA. As preocupações de hoje, em torno de uma superinteligência de máquina, não são novas. E não serão definitivas.\n\"Qualquer máquina verdadeiramente superinteligente que conseguisse melhorar recursivamente sua própria inteligência poderia aumentar suas capacidades tão rapidamente que, antes que alguém percebesse, ultrapassaria todo o entendimento e controle humanos. Além disso, qualquer máquina que pudesse fazer isso provavelmente esconderia todas as evidências de sua inteligência até que pudesse garantir sua existência contínua — inclusive a ponto de poder resistir a uma tentativa humana de desligar o plugue\", argumenta Rahul Matthan, sócio fundador do escritório de advocacia indiano Trilegal Partners.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTENDÊNCIA\nA regulação da IA é para ontem\nNo atual cenário competitivo, permitir que o desenvolvimento da IA continue sem regulamentação é, no mínimo, temerário. Se as empresas privadas precisam garantir que o desenvolvimento da IA ​​ocorra de maneira segura e controlada, elas não podem fazer isso enquanto competem em uma corrida existencial pela sobrevivência. Em vez disso, precisamos criar barreiras para que essa indústria opere — sacrificando, se necessário, alguns ganhos de curto prazo. Disso não há quem discorde. Os próprios executivos da OpenAI têm clamado por uma regulação.\nMas o direito anda sempre a reboque do desenvolvimento tecnológico. Hoje, a tentativa de legislação mais avançada é a da União Europeia. O Congresso brasileiro também já discute um marco legal. E o governo do Reino Unido acaba de publicar um documento com orientações parao uso de IA, de modo a impulsionar a inovação responsável e manter a confiança do público nessa tecnologia revolucionária. Em outubro, o Escritório de Política Científica e Tecnológica da Casa Branca publicou um Projeto para uma Declaração de Direitos da IA. No início desta semana, a presidente da FTC, Lina Khan, disse que a Federal Trade Commission estaria observando o setor para garantir a concorrência.\nRiscos como violação de direitos autorais, viés inerente a algoritmos generativos, superestimação das capacidades de IA, resultando na recepção ou disseminação de resultados incorretos (\"alucinações de IA\"), a criação de deep fakes e outros conteúdos sintéticos que poderiam manipular a opinião pública ou representar riscos para a segurança pública e preocupações complexas de privacidade demonstram a necessidade da governança responsável desses novos aplicativos quanto antes.\nJustamente por isso, cresce na comunidade de advogados e juristas a certeza de que o Chat-GPT está para a regulação da IA, assim como o smartphone, as redes sociais e os abusos no marketing digital estiveram para a regulação da privacidade. Enquanto esperamos por estruturas legais claras para abordar adequadamente a IA, todos nós, como indivíduos, podemos fazer algo a respeito.\nAs organizações, principalmente, precisam tomar medidas hoje para alinhar seu uso responsável da IA, incluindo intervenção humana, precisão, segurança, prevenção de vieses e explicabilidade da tomada de decisões automatizadas com os princípios de privacidade. Não é demitindo os times de IA Ética que chegaremos lá... Cabe às empresas fazer investimentos contínuos para aprimorar habilidades para auditoria algorítmica e integrar metodologias de \"ética, privacidade e segurança por design\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA educação para o bom uso da IA, também\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"Bons prompts são difíceis de escrever - você precisa de conhecimento básico\", declarou Amy Webb no palco do SXSW 2023. John Maeda foi pelo mesmo caminho, reforçando o que já vinhamos falando aqui: a IA mais inteligente é burra sem as pessoas. Modelos como o GPT-3 ainda não conseguem fazer (e talvez jamais façam) conexões abstratas entre o que cortam e colam. Por mais encantados que estejamos por eles, ainda dependem dos humanos.\nA capacidade de escrita ou criação de prompts (prompting) estará em alta nos próximos anos. Fala-se até na criação de um novo perfil profissional: o do(a) engenheiro(a) de prompt. A habilidade de prompting é tão poderosa que não será surpresa vê-la se tornar requisito padrão nas descrições de cargos em quase todos os setores. Seu futuro profissional pode depender de quão bem você souber falar com a IA.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPINIÃO\nNão é a tecnologia, mas o uso que fazemos dela\nTodos somos responsáveis. Cada um de nós, como usuários. As empresas por trás dos modelos. Aquelas que já fazem uso deles. Os reguladores, que precisam se interessar pela tecnologia e estudar, antes de legislar. Temos o dever de nos preocupar, mas não de espalhar pânico.\nNo fundo, a carta deve ter pouco efeito prático. Mas serve como instrumento para aquecer o debate na sociedade. \"Há muita conversa sobre 'Vamos desligar o plugue', mas não tenho certeza de que haja um único plugue\", disse Arati Prabhakar, diretor do Escritório de Política Científica e Tecnológica da Casa Branca, meses atrás.\nComo teriam sido os últimos três anos se no final de 2010 houvesse uma “pausa” na pesquisa de uma nova tecnologia radical de vacina chamada mRNA? É fundamental que não joguemos o bebê que aumenta a produtividade com a água do banho que preocupa a IA, diz  Daniel Castro, da Fundação de Tecnologia da Informação e Inovação, em um relatório intitulado “Ten Principles for Regulation That Does Not Harm AI Innovation\".\nParte do desafio é o problema do ritmo: a tecnologia se move mais rápido que a regulamentação e, portanto, os setores altamente regulamentados enfrentam os maiores obstáculos. Alguns setores da economia, como saúde, educação e transporte, são os que mais se beneficiam da IA, mas podem ser os mais lentos para mudar, ressalta James Pethokoukis.\nOutro problema, segundo ele, é que o medo em relação à tecnologia pode fazer com que os formuladores de políticas hesitem em adotá-la. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n Esta mensagem foi enviada para bernarducs@gmail.com. Atualize suas preferências.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique aqui.\r\n\r\nVeja nossa Política de Privacidade e Termos de Uso.\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}