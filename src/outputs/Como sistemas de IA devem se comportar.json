{"mail_id": 9795, "from": "=?utf-8?Q?The=20Shift?= <news@theshift.info>", "subject": "Como sistemas de IA devem se comportar", "date": "2023-02-22T11:54:34+00:00", "body": "Grandes modelos de linguagem e a Singularidade | Maturidade no uso está em alta | Como surfar o hype generativo | Um humano derrota a IA no Go |\r\n\r\n22/02/23  |  Assine The Shift (https://theshift.info/assinatura?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)   |  Abra no browser (https://mailchi.mp/theshift.info/como-sistemas-de-ia-devem-se-comportar?e=43a197caaf)\r\n\r\n\r\n** Inteligência Aumentada\r\n------------------------------------------------------------\r\n\r\n\r\n**\r\nOFERECIMENTO\r\n------------------------------------------------------------\r\nbernardo, bom dia!\r\nUsuários e empresas estão descobrindo que os grandes modelos de linguagem sofrem de inconsistências e, muitas vezes, não filtram conteúdos nocivos. Por isso, entendem que seu uso deve ser precedido de um debate sobre ética. Mas quem cria e aplica as regras necessárias?\r\n\r\nAinda nesta edição:\r\n* Grandes modelos de linguagem e a Singularidade (https://youtu.be/-lnHHWRCDGk?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n* Maturidade no uso está em alta, ainda bem\r\n* Como surfar bem a onda do hype generativo\r\n* Depois de sete anos, um humano derrota a IA no Go\r\n\r\nSe você quer apoiar as vítimas do Litoral Norte, segue alista das instituições (https://www.uol.com.br/ecoa/ultimas-noticias/2023/02/21/como-ajudar-as-vitimas-das-chuvas-do-litoral-doe-para-essas-instituicoes.htm?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) que participam deste mutirão e estão recebendo doações.\r\n\r\nBoa leitura.\r\n\r\n\r\n** Como sistemas de IA devem se comportar\r\n------------------------------------------------------------\r\n\r\nA corrida para incorporar ferramentas derivadas de grandes modelos de linguagem (como o GPT-3 e superiores (https://www.linkedin.com/feed/update/urn:li:activity:7034077312912433152/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ) aos fluxos de trabalho das empresas já começou. Mas da mesma forma que a mídia americana descobriu semana passada (https://www.politico.com/newsletters/digital-future-daily/2023/02/21/ai-chatbots-meet-the-press-00083830?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , também os usuários corporativos já perceberam que esses modelos nem sempre são factuais ou logicamente consistentes; têm conhecimento de eventos ocorridos após o seu treinamento ou são capazes de evitar discurso de ódio e outros conteúdos nocivos, só para citar mazelas recorrentes.\r\n\r\nA OpenAI, criadora do ChatGPT, sempre enfatizou que ele ainda é apenas um projeto de pesquisa, em evolução constante à medida que recebe o feedback das pessoas. O que não impediu a Microsoft de integrá-lo a uma nova versão do Bing — e decepcionar, após relatos dos primeiros beta testers. A ponto de implementar restrições significativas (https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Updates-to-Chat?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) — incluindo um limite de 50 respostas totais por dia, bem como cinco turnos de bate-papo por sessão — para tentar reprimir respostas desequilibradas que ela já sabia (https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) que ocorreriam.\r\n\r\nResultado: todo o hype em torno da IA Generativa e da incorporação dos chatbots às buscas aqueceu o debate sobre os riscos da IA, iniciando outra corrida, pela criação de regras e abordagens capazes de tornar ferramentas como o ChatGPT mais precisas, consistentes e atualizadas.\r\n\r\nEm Stanford, pesquisadores chegaram a três procedimentos (https://hai.stanford.edu/news/how-do-we-fix-and-update-large-language-models?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) (MEND (https://arxiv.org/abs/2110.11309?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , SERAC (https://arxiv.org/abs/2206.06520?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) e ConCoRD (https://arxiv.org/abs/2211.11875?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ) usados para filtrar as conexões neurais dos modelos e identificar quais precisam ser atualizados e/ou corrigidos. A intenção desses pesquisadores é conseguir editar comportamentos dos modelos. E, depois, tornar essa edição do modelo mais simples para os usuários. Por exemplo, seria bom especificar uma edição descrevendo-a em linguagem natural (“seja mais positivo sobre vacinas”) em vez de coletar um conjunto de dados de exemplos (por exemplo, uma série de declarações positivas sobre vacinas) com o qual treinar novamente o modelo.\r\n\r\nMas, na opinião da OpenAI, qualquer iniciativa nesse sentido precisa ser precedida de um debate maior o sobre quais regras devem ser aplicadas aos grandes modelos de linguagem e quem deve decidir criá-las e aplicá-las. Reflexões que já vem fazendo internamente.\r\n\r\nA empresa está trabalhando em um projeto experimental, apelidado de “Consensus Project”, no qual os pesquisadores da OpenAI estão analisando até que ponto as pessoas concordam ou discordam sobre diferentes informações geradas por seus modelos. O objetivo é ampliar os pontos de vista e as perspectivas representadas neles.\r\n\r\nA OpenAI acredita que conseguirá treinar modelos de IA para representar diferentes perspectivas e visões de mundo. Ou seja, em vez de ter um ChatGPT de tamanho único, pessoas e empresas poderiam usá-lo para gerar respostas alinhadas com suas próprias políticas. “É para lá que aspiramos chegar, mas será uma jornada longa e difícil chegar lá porque percebemos o quão desafiador é”, disseram dois de seus engenheiros (https://www.technologyreview.com/2023/02/21/1068893/how-openai-is-trying-to-make-chatgpt-safer-and-less-biased/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\nDesafiador e perigoso, convenhamos! Uma revisão recente de centenas de descrições de trabalho escritas usando o ChatGPT por Kieran Snyder, CEO da fabricante de software Textio, descobriu que quanto mais personalizado o prompt, mais atraente a saída da IA — e mais potencialmente tendenciosa.\r\n\r\nTalvez, por isso, Sam Altman, o CEO da OpenAI tenha tornado a defender publicamente a regulação da tecnologia (https://www.businessinsider.com/openai-chatgpt-sam-altman-world-not-far-potentially-scary-ai-2023-2?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) por trás de seus modelos. “Embora seja tentador avançar rapidamente, a sociedade precisa de tempo para se adaptar a algo tão grande”, escreveu ele em uma série de tuítes neste domingo (https://twitter.com/sama/status/1627110888321978368?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . Meses atrás, Mira Murati, CTO da OpenAI, também já havia dito em entrevista à revista Time (https://time.com/6252404/mira-murati-chatgpt-openai-interview/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  que o ChatGPT deveria ser regulamentado, pois poderia ser mal utilizado. Na opinião deles, está claro que precisaremos da formulação de políticas na velocidade da IA. O que dificilmente acontecerá.\r\n\r\nA audiência da Suprema Corte esta semana, sobre a liberdade de expressão on-line, levanta a questão (https://venturebeat.com/ai/could-big-tech-be-liable-for-generative-ai-output-hypothetically-yes-says-supreme-court-justice/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  de saber se as respostas de pesquisa com IA são protegidas pela Seção 230. Hipoteticamente, a IA Generativa pode não estar coberta por essa lei que protege as empresas de tecnologia de serem responsabilizadas por conteúdo online postado e compartilhado pelos usuários (https://time.com/6252404/mira-murati-chatgpt-openai-interview/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , de acordo com uma breve declaração do juiz da Neil M. Gorsuch.\r\n\r\nEntão, parte da tarefa imediata de criar regras que tornem as ferramentas de IA Generativa mais precisas, consistentes e atualizadas caberemos próprios desenvolvedores. Dias atrás, a OpenAi decidiu publicar esclarecimentos (https://openai.com/blog/how-should-ai-systems-behave/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) sobre como o comportamento do ChatGPT é moldado e como planeja melhorá-lo. E prometeu não parar por aí.\r\n\r\nPlayers iniciantes, como Jasper, um redator baseado em IA que criou ferramentas em cima do GPT e gerou uma receita estimada em US$ 75 milhões no ano passado, também estão lutando para se manter acima da onda e no controle de seus produtos. Os debates em sua conferência sobre IA Generativa (https://www.cnbc.com/2023/02/17/jasper-generative-ai-conference-in-san-francisco-what-was-it-like.html?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , realizada na semana passada, deixar isso bem claro.\r\n\r\nE você, o que está fazendo para tornar os modelos que usa mais confiáveis?\r\n\r\n\r\n** UM CONTEÚDO 7D ANALYITCS (https://www.sensedia.com.br/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n------------------------------------------------------------\r\n\r\n\r\n** Confiar, desconfiando\r\n------------------------------------------------------------\r\nO que faz as pessoas acreditarem nos resultados da IA? Segundo uma pesquisa do MIT, saber que a \"caixa preta\" (modelo/algoritmo) foi feita por pessoas que elas conhecem (https://mailchi.mp/theshift.info/o-que-nos-faz-confiar-na-ia?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . À primeira vista, a descoberta parece contraintuitiva. Imaginamos que as pessoas querem conhecer detalhes de como o algoritmo foi elaborado, certo?\r\n\r\nO time, portanto, pesa mais. Ao que parece, é a confiança nas pessoas que supervisionaram os dados, e na equipe de tecnologia que criou o algoritmo, que pesam na balança quando se trata de confiar no uso corporativo da IA nos negócios.\r\n\r\nPor outro lado, é preciso lembrar que a IA é uma tecnologia em constante evolução. É necessário um diálogo contínuo entre os desenvolvedores, usuários e reguladores da tecnologia, de modo a garantir que os sistemas de IA sejam responsáveis e confiáveis.\r\n\r\nQue tal colocar um pouco de lenha na fogueira? A confiança, como descrita na pesquisa, acontece, vemos isso em muitos dos nossos clientes. Mas ela precisa, na nossa opinião, ser precedida de um período saudável de desconfiança, experimentação e muitas perguntas:\r\n* “Os dados estão corretos?\"\r\n* “Fizemos todas as perguntas?\"\r\n* \"Estamos incluindo todo o ecossistema?\"\r\n* \"Eliminamos todos os vieses?\"\r\n\r\nÉ o que sinaliza também o estudo The Path to AI Maturity 2023, da LXT. (https://7521830.fs1.hubspotusercontent-na1.net/hubfs/7521830/Whitepapers/The%20Path%20to%20AI%20Maturity%202023.pdf?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) O estudo aponta que, em média, 46% de todos os projetos de IA ainda não atingem seus objetivos. Mas o sucesso (confiança+resultados) aumenta com a maturidade do uso das aplicações, após superar os desafios da implantação: equilibrar tecnologia (integração, dados de qualidade) e fatores humanos (talentos, treinamento).\r\n\r\nHá um dado muito interessante no estudo, sobre as diferentes taxas de fracasso dos projetos, por indústria. (gráfico acima). Manufatura e supply chain (uma das nossas especialidades (https://www.7danalytics.com.br/cases/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ) têm a menor taxa de fracasso (29%), porque já atravessaram as fases de questionamento e experimentação.\r\n\r\n\r\n** Grandes modelos de linguagem e a Singularidade\r\n------------------------------------------------------------\r\n\r\nhttps://youtu.be/-lnHHWRCDGk?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D\r\n\r\nO professor Christopher Potts (https://web.stanford.edu/~cgpotts/cv/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) é presidente do Departamento de Linguística da Universidade de Stanford. Nesta palestra, ele descreve o impressionante progresso dos modelos de aprendizado de máquina baseados nos Transformers (https://en.wikipedia.org/wiki/Transformer_?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D(machine_learning_model))  - conceito que teve um grande impacto no processamento da linguagem natural, levando ao desenvolvimento de produtos como o GPT-3 - e discute suas implicações na sociedade. De acordo com ele, vivemos a Era de Ouro da pesquisa de IA e grandes avanços ainda estão por vir. Ele também defende que um marco significativo foi alcançado nos últimos anos em direção à Singularidade (https://en.wikipedia.org/wiki/Technological_singularity?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , a partir da disponibilidade de uma gigantesca quantidade de dados para treinamento desses modelos.\r\n\r\n\r\n** INTELIGÊNCIA ARTIFICIAL\r\n------------------------------------------------------------\r\n\r\n\r\n** Maturidade no uso está em alta, ainda bem\r\n------------------------------------------------------------\r\n\r\nFazer com que os chatbots de conversação de IA, como o Chat GPT, soem humanos e convincentes está se mostrando mais fácil do que torná-los precisos, como mostraram os tropeços de lançamento público do Bard (Alphabet) e do Bing (Microsoft).\r\n\r\nQuando os chatbots fazem crowdsourcing na internet para criar uma narrativa de IA, inevitavelmente você enfrenta 'questões de verdade' e preconceitos inerentes à internet. Não é de surpreender que dois terços dos 300 executivos americanos participantes do estudo \"Path to AI Maturity 2023 (https://7521830.fs1.hubspotusercontent-na1.net/hubfs/7521830/Whitepapers/The%20Path%20to%20AI%20Maturity%202023.pdf?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) \", da LXT, digam que sua necessidade de dados de alta qualidade está aumentando à medida que modelos famintos de IA continuam devorando dados de treinamento para melhorar.\r\n\r\nAs boas notícias do estudo? As organizações evoluíram em suas jornadas de IA, com 48% dos entrevistados classificando-se no nível maduro, aonde a IA está em produção ou já faz parte do DNA comercial. Para conseguir isso, quase metade vem investindo US$ 76 milhões ou mais, anualmente, em IA, enquanto apenas 1% dos entrevistados gasta US$ 1 milhão ou menos. E mais de 80% implementaram uma estratégia de dados para impulsionar o sucesso de suas iniciativas de IA.\r\n\r\nAs soluções de processamento de linguagem natural (NLP) e reconhecimento de fala/voz são os aplicativos de IA mais implantados (com exceção de dois segmentos: serviços financeiros e supply chain), seguidos por análises preditivas e IA de conversação (CAI). E mais de 90% dizem que fizeram um progresso bom ou excelente no gerenciamento do viés da IA. Será? “A importância da IA ​​responsável está no topo da mente da maioria das organizações”, comentou Phil Hall, diretor de crescimento da LXT. “Tanto que a diversidade nos dados e na força de trabalho por trás deles é essencial para 90% dos participantes do estudo. Prestar atenção a uma estratégia de dados de qualidade que suporta IA nunca foi tão crítico\", completa.\r\n\r\nPara a maioria dos executivos entrevistados, a IA já é o passo seguinte na evolução da computação moderna e uma continuidade dos agora familiares aplicativos de computador orientados a dados, ou seja, aprendizado de máquina e análise preditiva.  E a “IA generativa”, mais um passo no desenvolvimento da IA moderna, ou seja, estudo profundo ou análise estatística de grandes quantidades de dados. Os resultados não são perfeitos, mas são mais do que bons o suficiente para melhorar a velocidade e a eficiência em tarefas mais rotineiras ou repetitivas. E falhar faz parte do processo de aprendizado das equipes e dos próprios modelos em uso.\r\n* Grandes escritórios de advocacia americanos estão usando uma ferramenta da OpenAI para pesquisar e escrever documentos legais. E estão satisfeitos com os resultados (https://www.wired.co.uk/article/generative-ai-is-coming-for-the-lawyers?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , apesar das falhas.\r\n\r\n\r\n** APLICAÇÃO\r\n------------------------------------------------------------\r\n\r\n\r\n** Como surfar bem a onda do hype generativo\r\n------------------------------------------------------------\r\n\r\nÉ um sonho ter sistemas que forneçam respostas corretas, inteligentemente, com conhecimento instantâneo e contexto em diferentes áreas do conhecimento. Mas é um pesadelo que esses sistemas possam dar respostas falsas com a mesma facilidade com que fornecem uma real. Portanto, LLM hoje significa uma revolução para as equipes de dados, obrigadas a equilibrar a promessa de conhecimento instantâneo com a necessidade de garantir proteção e confiabilidade.\r\n\r\nA Forrester acaba de publicar um relatório sobre IA Generativa (https://www.forrester.com/report/generative-ai-prompts-productivity-imagination-and-innovation-in-the-enterprise/RES178876?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  (pago) no qual aconselha seus clientes corporativos a não ignorarem ou minimizarem seu impacto. Seria “um erro caro”. Em resumo, na opinião da consultoria, a IA Generativa apresenta uma oportunidade de aprimorar e até mesmo automatizar os processos de trabalho existentes em TI, Marketing, atendimento ao cliente e outras funções de negócios. E as empresas precisam começar a experimentá-la, cercando-se se todos os cuidados, começando pela escolha de fornecedores. Isso significa:\r\n* Fazer as perguntas difíceis - Que modelo(s) ou API(s) o fornecedor está realmente usando (por exemplo, Davinci-003, BERT, GPT-J)? Para quais tarefas específicas de PNL seu produto foi projetado e como o LLM se encaixa nesse processo? Há quanto tempo utiliza os LLMs e quais benefícios seus clientes observaram? Quais medidas estão em vigor para detectar conteúdo impróprio? Quanto controle seus clientes terão sobre a saída ou isso é totalmente regido pelo modelo? Como o LLM pode ser ajustado ou personalizado para lidar com casos de uso específicos do domínio?\r\n\r\n* Saber que ter mais parâmetros não é necessariamente melhor - Para tarefas pontuais de treinamento (como treinar um modelo básico de linguagem natural ou gerar dados de treinamento off-line para uso por modelos menores), aproveitar os LLMs extremamente grandes faz todo o sentido. Para casos de uso online, no entanto, usar modelos muito grandes pode ser extremamente caro e, francamente, um exagero. Um LLM menor (1 a 10 bilhões de parâmetros) específico de domínio pode superar modelos maiores a um custo muito menor.\r\n\r\n* Prestar atenção para bolt-ons indiferenciados — Os modelos que ganharam a atenção da mídia são extremamente novos e, embora certamente estejamos vendo rodadas extremamente rápidas de experimentação e inovação, construir produtos valiosos leva tempo (e pesquisa, validação e teste). Esperamos ver muitos truques enigmáticos do ChatGPT nos próximos meses. Ao avaliar soluções que reivindicam integração com esses modelos generativos de alto perfil, pergunte-se: o que o fornecedor está mostrando é exclusivo dele?\r\n\r\n\r\n** Principais tendências martech para 2023\r\n------------------------------------------------------------\r\nhttps://martechmap.com/int_supergraphic?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D\r\n\r\nCinco grandes tendências moldarão Martech e Marketing em 2023, na opinião de Scott Brinker, do chiefmartec.com e Frans Riemersma, do MartechTribe (https://youtu.be/eqHNjX_J090?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , responsáveis pela criação e manutenção anual do Martech Landscape (https://martechmap.com/int_supergraphic?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) (acima), hoje com 10.383 fornecedores divididos em 49 categorias. São elas IA Generativa, ativação de data warehouses em nuvem, comunidades e ecossistemas, criadores sem código e Web3 e o metaverso.\r\n\r\nDe acordo com eles, a geração atual de produtos martech foi amplamente suportada por três grandes movimentos, que geraram grandes mudanças no mundo, na indústria de tecnologia e na profissão de marketing: SaaS, social media e dispositivos móveis. Agora, novos movimentos influenciarão o que está por vir:\r\n1. IA — Aprendizado de Máquina (https://en.wikipedia.org/wiki/Machine_learning?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) avançado e onipresente, IA Generativa (https://en.wikipedia.org/wiki/Synthetic_media?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) (como ChatGPT e Stable Diffusion) e uma ascensão constante para IA Geral (a AGI) (https://en.wikipedia.org/wiki/Artificial_general_intelligence?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) mudarão radicalmente o que as máquinas poderão fazer, tanto para profissionais de Marketing quanto para os consumidores (https://chiefmartec.com/2020/12/martech-2030-trend-5-harmonizing-human-machine/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ;\r\n2. Realidades Virtual e Aumentada — Remodelará completamente o que é possível com as experiências do cliente, desvinculadas das telas como as pensamos hoje;\r\n3. Composability — Por meio de APIs e no-code, o software se tornará muito mais maleável e permeável, enquanto os dados se tornarão muito mais fluidos e portáteis, permitindo que empresas e indivíduos “componham” facilmente soluções e/ou experiências personalizadas, em tempo real.\r\n4. Web3 — A descentralização e os ativos digitais permanentes e não replicáveis permitirão tipos muito diferentes de organizações e modelos de negócios.\r\n\r\nEsses movimentos farão com que os próximos sete anos na indústria e na profissão de martech superem os últimos sete anos em expansão, prevê Scott Brinker (https://chiefmartec.com/2023/01/2023-will-be-a-chaotic-year-for-martech-yet-the-start-of-a-massive-wave-of-growth/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n\r\n** PESQUISA\r\n------------------------------------------------------------\r\n\r\n\r\n** Depois de sete anos, um humano derrota a IA no Go\r\n------------------------------------------------------------\r\n\r\nForam, a todo, 15 partidas, mas, dessa vez, a IA só venceu uma (https://arstechnica.com/information-technology/2023/02/man-beats-machine-at-go-in-human-victory-over-ai/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . E o humano não era nenhum jogador profissional. Muito menos um campeão mundial. A tática de Kellin Pelrine para derrotar a máquina? Explorar uma falha no sistema, recém descoberta por outro computador. Uma espécie de ponto cego, que deu o jogador humano a vantagem necessária para superar a IA.\r\n\r\nPelrine criou um grande \"loop\" de pedras para cercar um grupo de pedras de seu oponente e depois distraí-lo fazendo movimentos em outras áreas do tabuleiro. Mesmo quando seu grupo estava quase cercado, o sistema não percebeu a estratégia. Algo que para jogadores humanos seria de fácil percepção, já que as pedras circundantes se destacam no tabuleiro.\r\n\r\nOK. Pelrine não chegou a enfrentar o AlphaGo, o sistema desenvolvido pela DeepMind, que derrotou o campeão mundial de Go Lee Sedol por quatro jogos a um em 2016. Mas os sistemas contra os quais jogou são equivalentes.\r\n\r\nNo final do ano passado, um estudante de doutorado de Berkeley, Adam Gleave, trabalhando com o eminente cientista da computação de Berkeley, Stuart Russell, descobriu uma maneira específica de falsificar dois dos melhores programas de Go: o KataGo (https://arxiv.org/abs/2211.00241?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) e o Leela Zero. O que eles fizeram foi ensiná-la a Pelrine, que a colocou em prática durante os jogos.\r\n\r\nA descoberta dessa fraqueza em alguns sistemas Go-play mais avançadas aponta para uma falha fundamental dos algoritmos de Deep Learning que sustentam s aplicações mais avançada de hoje, afirma Russell. \"Esses sistemas podem apenas 'entender' situações específicas às quais foram expostos no passado, mas são incapazes de generalizar da forma que os humanos fazem\", explica.\r\n\r\nA vitória de Pelrine é um lembrete de que, independente de quão boa seja a IA baseada em Deep Learnig quando treinada em uma imensa quantidade de dados, nunca teremos certeza de que sistemas desse tipo poderão estender o que sabem a novas circunstâncias. Vale para o jogo de GO, como vale para muitos desafios dos veículos autônomos e do uso de chatbots de IA como o ChatGPT e o Bard para buscas.\r\n* A propósito... a mais recente IA da DeepMind derrotou humanos no jogo Stratego (https://singularityhub.com/2022/12/05/deepminds-latest-ai-trounces-human-players-at-the-game-stratego/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , mais complicado para as máquinas do que xadrez ou Go.\r\n\r\n\r\n** Garimpo do dia\r\n------------------------------------------------------------\r\n* A Amazon Web Services e a Hugging Face anunciaram uma expansão de sua parceria (https://huggingface.co/blog/aws-partnership?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) que levará à construção de um modelo de linguagem de última geração na AWS (https://www.latimes.com/business/story/2023-02-21/amazons-aws-hugging-face-ai-deals-chatgpt?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . Um concorrente do ChatGPT, disponibilizado pela AWS com outros produtos Hugging Face para que seus usuários criem seus próprios aplicativos.\r\n\r\n* 49 ferramentas de IA que não são ChatGPT, mas você precisa conhecer (https://media.licdn.com/dms/document/C561FAQEAFOWr5hfMDw/feedshare-document-pdf-analyzed/0/1677054156158?e=1677715200&v=beta&t=hXMH29kVrgpLgJYwmvrFumdV14GNJKh82Jbx9Funiuo&utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Atenção: a empresa espanhola Eliminalia garante que “apaga o seu passado” da internet. Mas seus métodos são duvidosos (https://www.theguardian.com/world/2023/feb/17/spanish-firm-erase-past-internet-eliminalia-web?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Como usar o ChatGPT para automatizar totalmente o data scraping (https://medium.com/codingthesmartway-com-blog/how-to-use-chatgpt-to-fully-automate-web-scraping-6bb0dab97943?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  de páginas web?\r\n\r\n* Você já usa o Grammarly? Pois saiba que além de checar seus textos, ele também pode ajustar LLMs com os dados aos quais tem acesso (https://www.emergingtechbrew.com/stories/2023/02/09/grammarly-s-plans-for-the-generative-ai-boom?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Pesquisadores tentaram descobrir se a IA estaria criando sua própria linguagem. E chegaram a um primeiro veredito (https://www.lifewire.com/experts-wonder-if-ai-is-creating-its-own-language-5409230?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Artistas acabam de ganhar uma ferramenta capaz de identificar obras geradas por IA que copiem seu estilo: a Glaze (http://glaze.cs.uchicago.edu/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* O Copilot for Business já está acessível a todos que quiserem usá-lo (https://techcrunch.com/2023/02/14/githubs-copilot-for-business-is-now-generally-available/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , avisa o GitHub.\r\n\r\nRECEBA NOSSAS NEWSLETTERS (https://theshift.info/newsletter/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n\r\n============================================================\r\n Esta mensagem foi enviada para bernarducs@gmail.com. ** Atualize suas preferências (https://www.theshift.info/assinatura/meus-dados/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique ** aqui (https://theshift.us20.list-manage.com/unsubscribe?u=ea84232681227c5ec7971f469&id=7f93052ef8&e=43a197caaf&c=c7227b54e1)\r\n.\r\nVeja nossa ** Política de Privacidade (https://www.theshift.info/about/privacy?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\ne ** Termos de Uso (http://www.theshift.info/about/use?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n.\r\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\nComo sistemas de IA devem se comportar\n\n\n\nGrandes modelos de linguagem e a Singularidade | Maturidade no uso está em alta | Como surfar o hype generativo | Um humano derrota a IA no Go |\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n\r\n                            22/02/23  |  Assine The Shift  |  Abra no browser\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteligência Aumentada\n\r\nOFERECIMENTO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\nbernardo, bom dia!\r\n\nUsuários e empresas estão descobrindo que os grandes modelos de linguagem sofrem de inconsistências e, muitas vezes, não filtram conteúdos nocivos. Por isso, entendem que seu uso deve ser precedido de um debate sobre ética. Mas quem cria e aplica as regras necessárias? \nAinda nesta edição:  \n\nGrandes modelos de linguagem e a Singularidade\nMaturidade no uso está em alta, ainda bem \nComo surfar bem a onda do hype generativo\nDepois de sete anos, um humano derrota a IA no Go\n\nSe você quer apoiar as vítimas do Litoral Norte, segue a lista das instituições que participam deste mutirão e estão recebendo doações.\n\r\nBoa leitura.\r\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo sistemas de IA devem se comportar\n\nA corrida para incorporar ferramentas derivadas de grandes modelos de linguagem (como o GPT-3 e superiores) aos fluxos de trabalho das empresas já começou. Mas da mesma forma que a mídia americana descobriu semana passada, também os usuários corporativos já perceberam que esses modelos nem sempre são factuais ou logicamente consistentes; têm conhecimento de eventos ocorridos após o seu treinamento ou são capazes de evitar discurso de ódio e outros conteúdos nocivos, só para citar mazelas recorrentes. \nA OpenAI, criadora do ChatGPT, sempre enfatizou que ele ainda é apenas um projeto de pesquisa, em evolução constante à medida que recebe o feedback das pessoas. O que não impediu a Microsoft de integrá-lo a uma nova versão do Bing — e decepcionar, após relatos dos primeiros beta testers. A ponto de implementar restrições significativas — incluindo um limite de 50 respostas totais por dia, bem como cinco turnos de bate-papo por sessão — para tentar reprimir respostas desequilibradas que ela já sabia que ocorreriam.\nResultado: todo o hype em torno da IA Generativa e da incorporação dos chatbots às buscas aqueceu o debate sobre os riscos da IA, iniciando outra corrida, pela criação de regras e abordagens capazes de tornar ferramentas como o ChatGPT mais precisas, consistentes e atualizadas. \nEm Stanford, pesquisadores chegaram a três procedimentos (MEND, SERAC e ConCoRD) usados para filtrar as conexões neurais dos modelos e identificar quais precisam ser atualizados e/ou corrigidos. A intenção desses pesquisadores é conseguir editar comportamentos dos modelos. E, depois, tornar essa edição do modelo mais simples para os usuários. Por exemplo, seria bom especificar uma edição descrevendo-a em linguagem natural (“seja mais positivo sobre vacinas”) em vez de coletar um conjunto de dados de exemplos (por exemplo, uma série de declarações positivas sobre vacinas) com o qual treinar novamente o modelo.\nMas, na opinião da OpenAI, qualquer iniciativa nesse sentido precisa ser precedida de um debate maior o sobre quais regras devem ser aplicadas aos grandes modelos de linguagem e quem deve decidir criá-las e aplicá-las. Reflexões que já vem fazendo internamente.\nA empresa está trabalhando em um projeto experimental, apelidado de “Consensus Project”, no qual os pesquisadores da OpenAI estão analisando até que ponto as pessoas concordam ou discordam sobre diferentes informações geradas por seus modelos. O objetivo é ampliar os pontos de vista e as perspectivas representadas neles. \nA OpenAI acredita que conseguirá treinar modelos de IA para representar diferentes perspectivas e visões de mundo. Ou seja, em vez de ter um ChatGPT de tamanho único, pessoas e empresas poderiam usá-lo para gerar respostas alinhadas com suas próprias políticas. “É para lá que aspiramos chegar, mas será uma jornada longa e difícil chegar lá porque percebemos o quão desafiador é”, disseram dois de seus engenheiros. \nDesafiador e perigoso, convenhamos! Uma revisão recente de centenas de descrições de trabalho escritas usando o ChatGPT por Kieran Snyder, CEO da fabricante de software Textio, descobriu que quanto mais personalizado o prompt, mais atraente a saída da IA — e mais potencialmente tendenciosa.\nTalvez, por isso, Sam Altman, o CEO da OpenAI tenha tornado a defender publicamente a regulação da tecnologia por trás de seus modelos. “Embora seja tentador avançar rapidamente, a sociedade precisa de tempo para se adaptar a algo tão grande”, escreveu ele em uma série de tuítes neste domingo. Meses atrás, Mira Murati, CTO da OpenAI, também já havia dito em entrevista à revista Time que o ChatGPT deveria ser regulamentado, pois poderia ser mal utilizado. Na opinião deles, está claro que precisaremos da formulação de políticas na velocidade da IA. O que dificilmente acontecerá.\nA audiência da Suprema Corte esta semana, sobre a liberdade de expressão on-line, levanta a questão de saber se as respostas de pesquisa com IA são protegidas pela Seção 230. Hipoteticamente, a IA Generativa pode não estar coberta por essa lei que protege as empresas de tecnologia de serem responsabilizadas por conteúdo online postado e compartilhado pelos usuários, de acordo com uma breve declaração do juiz da Neil M. Gorsuch.\nEntão, parte da tarefa imediata de criar regras que tornem as ferramentas de IA Generativa mais precisas, consistentes e atualizadas caberemos próprios desenvolvedores. Dias atrás, a OpenAi decidiu publicar esclarecimentos sobre como o comportamento do ChatGPT é moldado e como planeja melhorá-lo. E prometeu não parar por aí. \nPlayers iniciantes, como Jasper, um redator baseado em IA que criou ferramentas em cima do GPT e gerou uma receita estimada em US$ 75 milhões no ano passado, também estão lutando para se manter acima da onda e no controle de seus produtos. Os debates em sua conferência sobre IA Generativa, realizada na semana passada, deixar isso bem claro. \nE você, o que está fazendo para tornar os modelos que usa mais confiáveis?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUM CONTEÚDO 7D ANALYITCS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiar, desconfiando\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO que faz as pessoas acreditarem nos resultados da IA? Segundo uma pesquisa do MIT, saber que a \"caixa preta\" (modelo/algoritmo) foi feita por pessoas que elas conhecem. À primeira vista, a descoberta parece contraintuitiva. Imaginamos que as pessoas querem conhecer detalhes de como o algoritmo foi elaborado, certo?\r\n\r\nO time, portanto, pesa mais. Ao que parece, é a confiança nas pessoas que supervisionaram os dados, e na equipe de tecnologia que criou o algoritmo, que pesam na balança quando se trata de confiar no uso corporativo da IA nos negócios.\nPor outro lado, é preciso lembrar que a IA é uma tecnologia em constante evolução. É necessário um diálogo contínuo entre os desenvolvedores, usuários e reguladores da tecnologia, de modo a garantir que os sistemas de IA sejam responsáveis e confiáveis.\nQue tal colocar um pouco de lenha na fogueira? A confiança, como descrita na pesquisa, acontece, vemos isso em muitos dos nossos clientes. Mas ela precisa, na nossa opinião, ser precedida de um período saudável de desconfiança, experimentação e muitas perguntas: \n\n“Os dados estão corretos?\"\n“Fizemos todas as perguntas?\"\n\"Estamos incluindo todo o ecossistema?\"\n\"Eliminamos todos os vieses?\"\n\nÉ o que sinaliza também o estudo The Path to AI Maturity 2023, da LXT. O estudo aponta que, em média, 46% de todos os projetos de IA ainda não atingem seus objetivos. Mas o sucesso (confiança+resultados) aumenta com a maturidade do uso das aplicações, após superar os desafios da implantação: equilibrar tecnologia (integração, dados de qualidade) e fatores humanos (talentos, treinamento).\nHá um dado muito interessante no estudo, sobre as diferentes taxas de fracasso dos projetos, por indústria. (gráfico acima). Manufatura e supply chain (uma das nossas especialidades) têm a menor taxa de fracasso (29%), porque já atravessaram as fases de questionamento e experimentação. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrandes modelos de linguagem e a Singularidade\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO professor Christopher Potts é presidente do Departamento de Linguística da Universidade de Stanford. Nesta palestra, ele descreve o impressionante progresso dos modelos de aprendizado de máquina baseados nos Transformers - conceito que teve um grande impacto no processamento da linguagem natural, levando ao desenvolvimento de produtos como o GPT-3 - e discute suas implicações na sociedade. De acordo com ele, vivemos a Era de Ouro da pesquisa de IA e grandes avanços ainda estão por vir. Ele também defende que um marco significativo foi alcançado nos últimos anos em direção à Singularidade, a partir da disponibilidade de uma gigantesca quantidade de dados para treinamento desses modelos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nINTELIGÊNCIA ARTIFICIAL\nMaturidade no uso está em alta, ainda bem\nFazer com que os chatbots de conversação de IA, como o Chat GPT, soem humanos e convincentes está se mostrando mais fácil do que torná-los precisos, como mostraram os tropeços de lançamento público do Bard (Alphabet) e do Bing (Microsoft). \nQuando os chatbots fazem crowdsourcing na internet para criar uma narrativa de IA, inevitavelmente você enfrenta 'questões de verdade' e preconceitos inerentes à internet. Não é de surpreender que dois terços dos 300 executivos americanos participantes do estudo \"Path to AI Maturity 2023\", da LXT, digam que sua necessidade de dados de alta qualidade está aumentando à medida que modelos famintos de IA continuam devorando dados de treinamento para melhorar.\nAs boas notícias do estudo? As organizações evoluíram em suas jornadas de IA, com 48% dos entrevistados classificando-se no nível maduro, aonde a IA está em produção ou já faz parte do DNA comercial. Para conseguir isso, quase metade vem investindo US$ 76 milhões ou mais, anualmente, em IA, enquanto apenas 1% dos entrevistados gasta US$ 1 milhão ou menos. E mais de 80% implementaram uma estratégia de dados para impulsionar o sucesso de suas iniciativas de IA.\nAs soluções de processamento de linguagem natural (NLP) e reconhecimento de fala/voz são os aplicativos de IA mais implantados (com exceção de dois segmentos: serviços financeiros e supply chain), seguidos por análises preditivas e IA de conversação (CAI). E mais de 90% dizem que fizeram um progresso bom ou excelente no gerenciamento do viés da IA. Será? “A importância da IA ​​responsável está no topo da mente da maioria das organizações”, comentou Phil Hall, diretor de crescimento da LXT. “Tanto que a diversidade nos dados e na força de trabalho por trás deles é essencial para 90% dos participantes do estudo. Prestar atenção a uma estratégia de dados de qualidade que suporta IA nunca foi tão crítico\", completa.\nPara a maioria dos executivos entrevistados, a IA já é o passo seguinte na evolução da computação moderna e uma continuidade dos agora familiares aplicativos de computador orientados a dados, ou seja, aprendizado de máquina e análise preditiva.  E a “IA generativa”, mais um passo no desenvolvimento da IA moderna, ou seja, estudo profundo ou análise estatística de grandes quantidades de dados. Os resultados não são perfeitos, mas são mais do que bons o suficiente para melhorar a velocidade e a eficiência em tarefas mais rotineiras ou repetitivas. E falhar faz parte do processo de aprendizado das equipes e dos próprios modelos em uso.\n\nGrandes escritórios de advocacia americanos estão usando uma ferramenta da OpenAI para pesquisar e escrever documentos legais. E estão satisfeitos com os resultados, apesar das falhas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPLICAÇÃO\nComo surfar bem a onda do hype generativo\nÉ um sonho ter sistemas que forneçam respostas corretas, inteligentemente, com conhecimento instantâneo e contexto em diferentes áreas do conhecimento. Mas é um pesadelo que esses sistemas possam dar respostas falsas com a mesma facilidade com que fornecem uma real. Portanto, LLM hoje significa uma revolução para as equipes de dados, obrigadas a equilibrar a promessa de conhecimento instantâneo com a necessidade de garantir proteção e confiabilidade.\nA Forrester acaba de publicar um relatório sobre IA Generativa (pago) no qual aconselha seus clientes corporativos a não ignorarem ou minimizarem seu impacto. Seria “um erro caro”. Em resumo, na opinião da consultoria, a IA Generativa apresenta uma oportunidade de aprimorar e até mesmo automatizar os processos de trabalho existentes em TI, Marketing, atendimento ao cliente e outras funções de negócios. E as empresas precisam começar a experimentá-la, cercando-se se todos os cuidados, começando pela escolha de fornecedores. Isso significa:\n\nFazer as perguntas difíceis - Que modelo(s) ou API(s) o fornecedor está realmente usando (por exemplo, Davinci-003, BERT, GPT-J)? Para quais tarefas específicas de PNL seu produto foi projetado e como o LLM se encaixa nesse processo? Há quanto tempo utiliza os LLMs e quais benefícios seus clientes observaram? Quais medidas estão em vigor para detectar conteúdo impróprio? Quanto controle seus clientes terão sobre a saída ou isso é totalmente regido pelo modelo? Como o LLM pode ser ajustado ou personalizado para lidar com casos de uso específicos do domínio?\r\n\t \nSaber que ter mais parâmetros não é necessariamente melhor - Para tarefas pontuais de treinamento (como treinar um modelo básico de linguagem natural ou gerar dados de treinamento off-line para uso por modelos menores), aproveitar os LLMs extremamente grandes faz todo o sentido. Para casos de uso online, no entanto, usar modelos muito grandes pode ser extremamente caro e, francamente, um exagero. Um LLM menor (1 a 10 bilhões de parâmetros) específico de domínio pode superar modelos maiores a um custo muito menor.\r\n\t \nPrestar atenção para bolt-ons indiferenciados — Os modelos que ganharam a atenção da mídia são extremamente novos e, embora certamente estejamos vendo rodadas extremamente rápidas de experimentação e inovação, construir produtos valiosos leva tempo (e pesquisa, validação e teste). Esperamos ver muitos truques enigmáticos do ChatGPT nos próximos meses. Ao avaliar soluções que reivindicam integração com esses modelos generativos de alto perfil, pergunte-se: o que o fornecedor está mostrando é exclusivo dele? \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipais tendências martech para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCinco grandes tendências moldarão Martech e Marketing em 2023, na opinião de Scott Brinker, do chiefmartec.com e Frans Riemersma, do MartechTribe, responsáveis pela criação e manutenção anual do Martech Landscape (acima), hoje com 10.383 fornecedores divididos em 49 categorias. São elas IA Generativa, ativação de data warehouses em nuvem, comunidades e ecossistemas, criadores sem código e Web3 e o metaverso. \nDe acordo com eles, a geração atual de produtos martech foi amplamente suportada por três grandes movimentos, que geraram grandes mudanças no mundo, na indústria de tecnologia e na profissão de marketing: SaaS, social media e dispositivos móveis. Agora, novos movimentos influenciarão o que está por vir:\n\nIA — Aprendizado de Máquina avançado e onipresente, IA Generativa (como ChatGPT e Stable Diffusion) e uma ascensão constante para IA Geral (a AGI) mudarão radicalmente o que as máquinas poderão fazer, tanto para profissionais de Marketing quanto para os consumidores;\nRealidades Virtual e Aumentada — Remodelará completamente o que é possível com as experiências do cliente, desvinculadas das telas como as pensamos hoje;\nComposability — Por meio de APIs e no-code, o software se tornará muito mais maleável e permeável, enquanto os dados se tornarão muito mais fluidos e portáteis, permitindo que empresas e indivíduos “componham” facilmente soluções e/ou experiências personalizadas, em tempo real.\nWeb3 — A descentralização e os ativos digitais permanentes e não replicáveis permitirão tipos muito diferentes de organizações e modelos de negócios.\n\nEsses movimentos farão com que os próximos sete anos na indústria e na profissão de martech superem os últimos sete anos em expansão, prevê Scott Brinker.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPESQUISA\nDepois de sete anos, um humano derrota a IA no Go\nForam, a todo, 15 partidas, mas, dessa vez, a IA só venceu uma. E o humano não era nenhum jogador profissional. Muito menos um campeão mundial. A tática de Kellin Pelrine para derrotar a máquina? Explorar uma falha no sistema, recém descoberta por outro computador. Uma espécie de ponto cego, que deu o jogador humano a vantagem necessária para superar a IA.\nPelrine criou um grande \"loop\" de pedras para cercar um grupo de pedras de seu oponente e depois distraí-lo fazendo movimentos em outras áreas do tabuleiro. Mesmo quando seu grupo estava quase cercado, o sistema não percebeu a estratégia. Algo que para jogadores humanos seria de fácil percepção, já que as pedras circundantes se destacam no tabuleiro.\nOK. Pelrine não chegou a enfrentar o AlphaGo, o sistema desenvolvido pela DeepMind, que derrotou o campeão mundial de Go Lee Sedol por quatro jogos a um em 2016. Mas os sistemas contra os quais jogou são equivalentes.\nNo final do ano passado, um estudante de doutorado de Berkeley, Adam Gleave, trabalhando com o eminente cientista da computação de Berkeley, Stuart Russell, descobriu uma maneira específica de falsificar dois dos melhores programas de Go: o KataGo e o Leela Zero. O que eles fizeram foi ensiná-la a Pelrine, que a colocou em prática durante os jogos.\nA descoberta dessa fraqueza em alguns sistemas Go-play mais avançadas aponta para uma falha fundamental dos algoritmos de Deep Learning que sustentam s aplicações mais avançada de hoje, afirma Russell. \"Esses sistemas podem apenas 'entender' situações específicas às quais foram expostos no passado, mas são incapazes de generalizar da forma que os humanos fazem\", explica.\nA vitória de Pelrine é um lembrete de que, independente de quão boa seja a IA baseada em Deep Learnig quando treinada em uma imensa quantidade de dados, nunca teremos certeza de que sistemas desse tipo poderão estender o que sabem a novas circunstâncias. Vale para o jogo de GO, como vale para muitos desafios dos veículos autônomos e do uso de chatbots de IA como o ChatGPT e o Bard para buscas. \n\nA propósito... a mais recente IA da DeepMind derrotou humanos no jogo Stratego, mais complicado para as máquinas do que xadrez ou Go.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGarimpo do dia\n\nA Amazon Web Services e a Hugging Face anunciaram uma expansão de sua parceria que levará à construção de um modelo de linguagem de última geração na AWS. Um concorrente do ChatGPT, disponibilizado pela AWS com outros produtos Hugging Face para que seus usuários criem seus próprios aplicativos.\r\n\t \n49 ferramentas de IA que não são ChatGPT, mas você precisa conhecer. \r\n\t \nAtenção: a empresa espanhola Eliminalia garante que “apaga o seu passado” da internet. Mas seus métodos são duvidosos.\r\n\t \nComo usar o ChatGPT para automatizar totalmente o data scraping de páginas web?\r\n\t \nVocê já usa o Grammarly? Pois saiba que além de checar seus textos, ele também pode ajustar LLMs com os dados aos quais tem acesso.\r\n\t \nPesquisadores tentaram descobrir se a IA estaria criando sua própria linguagem. E chegaram a um primeiro veredito.\r\n\t \nArtistas acabam de ganhar uma ferramenta capaz de identificar obras geradas por IA que copiem seu estilo: a Glaze.\r\n\t \nO Copilot for Business já está acessível a todos que quiserem usá-lo, avisa o GitHub.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRECEBA NOSSAS NEWSLETTERS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n Esta mensagem foi enviada para bernarducs@gmail.com. Atualize suas preferências.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique aqui.\r\n\r\nVeja nossa Política de Privacidade e Termos de Uso.\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrandes modelos de linguagem e a Singularidade | Maturidade no uso está em alta | Como surfar o hype generativo | Um humano derrota a IA no Go |\r\n\r\n22/02/23  |  Assine The Shift (https://theshift.info/assinatura?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)   |  Abra no browser (https://mailchi.mp/theshift.info/como-sistemas-de-ia-devem-se-comportar?e=43a197caaf)\r\n\r\n\r\n** Inteligência Aumentada\r\n------------------------------------------------------------\r\n\r\n\r\n**\r\nOFERECIMENTO\r\n------------------------------------------------------------\r\nbernardo, bom dia!\r\nUsuários e empresas estão descobrindo que os grandes modelos de linguagem sofrem de inconsistências e, muitas vezes, não filtram conteúdos nocivos. Por isso, entendem que seu uso deve ser precedido de um debate sobre ética. Mas quem cria e aplica as regras necessárias?\r\n\r\nAinda nesta edição:\r\n* Grandes modelos de linguagem e a Singularidade (https://youtu.be/-lnHHWRCDGk?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n* Maturidade no uso está em alta, ainda bem\r\n* Como surfar bem a onda do hype generativo\r\n* Depois de sete anos, um humano derrota a IA no Go\r\n\r\nSe você quer apoiar as vítimas do Litoral Norte, segue alista das instituições (https://www.uol.com.br/ecoa/ultimas-noticias/2023/02/21/como-ajudar-as-vitimas-das-chuvas-do-litoral-doe-para-essas-instituicoes.htm?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) que participam deste mutirão e estão recebendo doações.\r\n\r\nBoa leitura.\r\n\r\n\r\n** Como sistemas de IA devem se comportar\r\n------------------------------------------------------------\r\n\r\nA corrida para incorporar ferramentas derivadas de grandes modelos de linguagem (como o GPT-3 e superiores (https://www.linkedin.com/feed/update/urn:li:activity:7034077312912433152/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ) aos fluxos de trabalho das empresas já começou. Mas da mesma forma que a mídia americana descobriu semana passada (https://www.politico.com/newsletters/digital-future-daily/2023/02/21/ai-chatbots-meet-the-press-00083830?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , também os usuários corporativos já perceberam que esses modelos nem sempre são factuais ou logicamente consistentes; têm conhecimento de eventos ocorridos após o seu treinamento ou são capazes de evitar discurso de ódio e outros conteúdos nocivos, só para citar mazelas recorrentes.\r\n\r\nA OpenAI, criadora do ChatGPT, sempre enfatizou que ele ainda é apenas um projeto de pesquisa, em evolução constante à medida que recebe o feedback das pessoas. O que não impediu a Microsoft de integrá-lo a uma nova versão do Bing — e decepcionar, após relatos dos primeiros beta testers. A ponto de implementar restrições significativas (https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Updates-to-Chat?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) — incluindo um limite de 50 respostas totais por dia, bem como cinco turnos de bate-papo por sessão — para tentar reprimir respostas desequilibradas que ela já sabia (https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) que ocorreriam.\r\n\r\nResultado: todo o hype em torno da IA Generativa e da incorporação dos chatbots às buscas aqueceu o debate sobre os riscos da IA, iniciando outra corrida, pela criação de regras e abordagens capazes de tornar ferramentas como o ChatGPT mais precisas, consistentes e atualizadas.\r\n\r\nEm Stanford, pesquisadores chegaram a três procedimentos (https://hai.stanford.edu/news/how-do-we-fix-and-update-large-language-models?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) (MEND (https://arxiv.org/abs/2110.11309?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , SERAC (https://arxiv.org/abs/2206.06520?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) e ConCoRD (https://arxiv.org/abs/2211.11875?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ) usados para filtrar as conexões neurais dos modelos e identificar quais precisam ser atualizados e/ou corrigidos. A intenção desses pesquisadores é conseguir editar comportamentos dos modelos. E, depois, tornar essa edição do modelo mais simples para os usuários. Por exemplo, seria bom especificar uma edição descrevendo-a em linguagem natural (“seja mais positivo sobre vacinas”) em vez de coletar um conjunto de dados de exemplos (por exemplo, uma série de declarações positivas sobre vacinas) com o qual treinar novamente o modelo.\r\n\r\nMas, na opinião da OpenAI, qualquer iniciativa nesse sentido precisa ser precedida de um debate maior o sobre quais regras devem ser aplicadas aos grandes modelos de linguagem e quem deve decidir criá-las e aplicá-las. Reflexões que já vem fazendo internamente.\r\n\r\nA empresa está trabalhando em um projeto experimental, apelidado de “Consensus Project”, no qual os pesquisadores da OpenAI estão analisando até que ponto as pessoas concordam ou discordam sobre diferentes informações geradas por seus modelos. O objetivo é ampliar os pontos de vista e as perspectivas representadas neles.\r\n\r\nA OpenAI acredita que conseguirá treinar modelos de IA para representar diferentes perspectivas e visões de mundo. Ou seja, em vez de ter um ChatGPT de tamanho único, pessoas e empresas poderiam usá-lo para gerar respostas alinhadas com suas próprias políticas. “É para lá que aspiramos chegar, mas será uma jornada longa e difícil chegar lá porque percebemos o quão desafiador é”, disseram dois de seus engenheiros (https://www.technologyreview.com/2023/02/21/1068893/how-openai-is-trying-to-make-chatgpt-safer-and-less-biased/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\nDesafiador e perigoso, convenhamos! Uma revisão recente de centenas de descrições de trabalho escritas usando o ChatGPT por Kieran Snyder, CEO da fabricante de software Textio, descobriu que quanto mais personalizado o prompt, mais atraente a saída da IA — e mais potencialmente tendenciosa.\r\n\r\nTalvez, por isso, Sam Altman, o CEO da OpenAI tenha tornado a defender publicamente a regulação da tecnologia (https://www.businessinsider.com/openai-chatgpt-sam-altman-world-not-far-potentially-scary-ai-2023-2?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) por trás de seus modelos. “Embora seja tentador avançar rapidamente, a sociedade precisa de tempo para se adaptar a algo tão grande”, escreveu ele em uma série de tuítes neste domingo (https://twitter.com/sama/status/1627110888321978368?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . Meses atrás, Mira Murati, CTO da OpenAI, também já havia dito em entrevista à revista Time (https://time.com/6252404/mira-murati-chatgpt-openai-interview/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  que o ChatGPT deveria ser regulamentado, pois poderia ser mal utilizado. Na opinião deles, está claro que precisaremos da formulação de políticas na velocidade da IA. O que dificilmente acontecerá.\r\n\r\nA audiência da Suprema Corte esta semana, sobre a liberdade de expressão on-line, levanta a questão (https://venturebeat.com/ai/could-big-tech-be-liable-for-generative-ai-output-hypothetically-yes-says-supreme-court-justice/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  de saber se as respostas de pesquisa com IA são protegidas pela Seção 230. Hipoteticamente, a IA Generativa pode não estar coberta por essa lei que protege as empresas de tecnologia de serem responsabilizadas por conteúdo online postado e compartilhado pelos usuários (https://time.com/6252404/mira-murati-chatgpt-openai-interview/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , de acordo com uma breve declaração do juiz da Neil M. Gorsuch.\r\n\r\nEntão, parte da tarefa imediata de criar regras que tornem as ferramentas de IA Generativa mais precisas, consistentes e atualizadas caberemos próprios desenvolvedores. Dias atrás, a OpenAi decidiu publicar esclarecimentos (https://openai.com/blog/how-should-ai-systems-behave/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) sobre como o comportamento do ChatGPT é moldado e como planeja melhorá-lo. E prometeu não parar por aí.\r\n\r\nPlayers iniciantes, como Jasper, um redator baseado em IA que criou ferramentas em cima do GPT e gerou uma receita estimada em US$ 75 milhões no ano passado, também estão lutando para se manter acima da onda e no controle de seus produtos. Os debates em sua conferência sobre IA Generativa (https://www.cnbc.com/2023/02/17/jasper-generative-ai-conference-in-san-francisco-what-was-it-like.html?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , realizada na semana passada, deixar isso bem claro.\r\n\r\nE você, o que está fazendo para tornar os modelos que usa mais confiáveis?\r\n\r\n\r\n** UM CONTEÚDO 7D ANALYITCS (https://www.sensedia.com.br/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n------------------------------------------------------------\r\n\r\n\r\n** Confiar, desconfiando\r\n------------------------------------------------------------\r\nO que faz as pessoas acreditarem nos resultados da IA? Segundo uma pesquisa do MIT, saber que a \"caixa preta\" (modelo/algoritmo) foi feita por pessoas que elas conhecem (https://mailchi.mp/theshift.info/o-que-nos-faz-confiar-na-ia?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . À primeira vista, a descoberta parece contraintuitiva. Imaginamos que as pessoas querem conhecer detalhes de como o algoritmo foi elaborado, certo?\r\n\r\nO time, portanto, pesa mais. Ao que parece, é a confiança nas pessoas que supervisionaram os dados, e na equipe de tecnologia que criou o algoritmo, que pesam na balança quando se trata de confiar no uso corporativo da IA nos negócios.\r\n\r\nPor outro lado, é preciso lembrar que a IA é uma tecnologia em constante evolução. É necessário um diálogo contínuo entre os desenvolvedores, usuários e reguladores da tecnologia, de modo a garantir que os sistemas de IA sejam responsáveis e confiáveis.\r\n\r\nQue tal colocar um pouco de lenha na fogueira? A confiança, como descrita na pesquisa, acontece, vemos isso em muitos dos nossos clientes. Mas ela precisa, na nossa opinião, ser precedida de um período saudável de desconfiança, experimentação e muitas perguntas:\r\n* “Os dados estão corretos?\"\r\n* “Fizemos todas as perguntas?\"\r\n* \"Estamos incluindo todo o ecossistema?\"\r\n* \"Eliminamos todos os vieses?\"\r\n\r\nÉ o que sinaliza também o estudo The Path to AI Maturity 2023, da LXT. (https://7521830.fs1.hubspotusercontent-na1.net/hubfs/7521830/Whitepapers/The%20Path%20to%20AI%20Maturity%202023.pdf?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) O estudo aponta que, em média, 46% de todos os projetos de IA ainda não atingem seus objetivos. Mas o sucesso (confiança+resultados) aumenta com a maturidade do uso das aplicações, após superar os desafios da implantação: equilibrar tecnologia (integração, dados de qualidade) e fatores humanos (talentos, treinamento).\r\n\r\nHá um dado muito interessante no estudo, sobre as diferentes taxas de fracasso dos projetos, por indústria. (gráfico acima). Manufatura e supply chain (uma das nossas especialidades (https://www.7danalytics.com.br/cases/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ) têm a menor taxa de fracasso (29%), porque já atravessaram as fases de questionamento e experimentação.\r\n\r\n\r\n** Grandes modelos de linguagem e a Singularidade\r\n------------------------------------------------------------\r\n\r\nhttps://youtu.be/-lnHHWRCDGk?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D\r\n\r\nO professor Christopher Potts (https://web.stanford.edu/~cgpotts/cv/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) é presidente do Departamento de Linguística da Universidade de Stanford. Nesta palestra, ele descreve o impressionante progresso dos modelos de aprendizado de máquina baseados nos Transformers (https://en.wikipedia.org/wiki/Transformer_?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D(machine_learning_model))  - conceito que teve um grande impacto no processamento da linguagem natural, levando ao desenvolvimento de produtos como o GPT-3 - e discute suas implicações na sociedade. De acordo com ele, vivemos a Era de Ouro da pesquisa de IA e grandes avanços ainda estão por vir. Ele também defende que um marco significativo foi alcançado nos últimos anos em direção à Singularidade (https://en.wikipedia.org/wiki/Technological_singularity?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , a partir da disponibilidade de uma gigantesca quantidade de dados para treinamento desses modelos.\r\n\r\n\r\n** INTELIGÊNCIA ARTIFICIAL\r\n------------------------------------------------------------\r\n\r\n\r\n** Maturidade no uso está em alta, ainda bem\r\n------------------------------------------------------------\r\n\r\nFazer com que os chatbots de conversação de IA, como o Chat GPT, soem humanos e convincentes está se mostrando mais fácil do que torná-los precisos, como mostraram os tropeços de lançamento público do Bard (Alphabet) e do Bing (Microsoft).\r\n\r\nQuando os chatbots fazem crowdsourcing na internet para criar uma narrativa de IA, inevitavelmente você enfrenta 'questões de verdade' e preconceitos inerentes à internet. Não é de surpreender que dois terços dos 300 executivos americanos participantes do estudo \"Path to AI Maturity 2023 (https://7521830.fs1.hubspotusercontent-na1.net/hubfs/7521830/Whitepapers/The%20Path%20to%20AI%20Maturity%202023.pdf?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) \", da LXT, digam que sua necessidade de dados de alta qualidade está aumentando à medida que modelos famintos de IA continuam devorando dados de treinamento para melhorar.\r\n\r\nAs boas notícias do estudo? As organizações evoluíram em suas jornadas de IA, com 48% dos entrevistados classificando-se no nível maduro, aonde a IA está em produção ou já faz parte do DNA comercial. Para conseguir isso, quase metade vem investindo US$ 76 milhões ou mais, anualmente, em IA, enquanto apenas 1% dos entrevistados gasta US$ 1 milhão ou menos. E mais de 80% implementaram uma estratégia de dados para impulsionar o sucesso de suas iniciativas de IA.\r\n\r\nAs soluções de processamento de linguagem natural (NLP) e reconhecimento de fala/voz são os aplicativos de IA mais implantados (com exceção de dois segmentos: serviços financeiros e supply chain), seguidos por análises preditivas e IA de conversação (CAI). E mais de 90% dizem que fizeram um progresso bom ou excelente no gerenciamento do viés da IA. Será? “A importância da IA ​​responsável está no topo da mente da maioria das organizações”, comentou Phil Hall, diretor de crescimento da LXT. “Tanto que a diversidade nos dados e na força de trabalho por trás deles é essencial para 90% dos participantes do estudo. Prestar atenção a uma estratégia de dados de qualidade que suporta IA nunca foi tão crítico\", completa.\r\n\r\nPara a maioria dos executivos entrevistados, a IA já é o passo seguinte na evolução da computação moderna e uma continuidade dos agora familiares aplicativos de computador orientados a dados, ou seja, aprendizado de máquina e análise preditiva.  E a “IA generativa”, mais um passo no desenvolvimento da IA moderna, ou seja, estudo profundo ou análise estatística de grandes quantidades de dados. Os resultados não são perfeitos, mas são mais do que bons o suficiente para melhorar a velocidade e a eficiência em tarefas mais rotineiras ou repetitivas. E falhar faz parte do processo de aprendizado das equipes e dos próprios modelos em uso.\r\n* Grandes escritórios de advocacia americanos estão usando uma ferramenta da OpenAI para pesquisar e escrever documentos legais. E estão satisfeitos com os resultados (https://www.wired.co.uk/article/generative-ai-is-coming-for-the-lawyers?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , apesar das falhas.\r\n\r\n\r\n** APLICAÇÃO\r\n------------------------------------------------------------\r\n\r\n\r\n** Como surfar bem a onda do hype generativo\r\n------------------------------------------------------------\r\n\r\nÉ um sonho ter sistemas que forneçam respostas corretas, inteligentemente, com conhecimento instantâneo e contexto em diferentes áreas do conhecimento. Mas é um pesadelo que esses sistemas possam dar respostas falsas com a mesma facilidade com que fornecem uma real. Portanto, LLM hoje significa uma revolução para as equipes de dados, obrigadas a equilibrar a promessa de conhecimento instantâneo com a necessidade de garantir proteção e confiabilidade.\r\n\r\nA Forrester acaba de publicar um relatório sobre IA Generativa (https://www.forrester.com/report/generative-ai-prompts-productivity-imagination-and-innovation-in-the-enterprise/RES178876?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  (pago) no qual aconselha seus clientes corporativos a não ignorarem ou minimizarem seu impacto. Seria “um erro caro”. Em resumo, na opinião da consultoria, a IA Generativa apresenta uma oportunidade de aprimorar e até mesmo automatizar os processos de trabalho existentes em TI, Marketing, atendimento ao cliente e outras funções de negócios. E as empresas precisam começar a experimentá-la, cercando-se se todos os cuidados, começando pela escolha de fornecedores. Isso significa:\r\n* Fazer as perguntas difíceis - Que modelo(s) ou API(s) o fornecedor está realmente usando (por exemplo, Davinci-003, BERT, GPT-J)? Para quais tarefas específicas de PNL seu produto foi projetado e como o LLM se encaixa nesse processo? Há quanto tempo utiliza os LLMs e quais benefícios seus clientes observaram? Quais medidas estão em vigor para detectar conteúdo impróprio? Quanto controle seus clientes terão sobre a saída ou isso é totalmente regido pelo modelo? Como o LLM pode ser ajustado ou personalizado para lidar com casos de uso específicos do domínio?\r\n\r\n* Saber que ter mais parâmetros não é necessariamente melhor - Para tarefas pontuais de treinamento (como treinar um modelo básico de linguagem natural ou gerar dados de treinamento off-line para uso por modelos menores), aproveitar os LLMs extremamente grandes faz todo o sentido. Para casos de uso online, no entanto, usar modelos muito grandes pode ser extremamente caro e, francamente, um exagero. Um LLM menor (1 a 10 bilhões de parâmetros) específico de domínio pode superar modelos maiores a um custo muito menor.\r\n\r\n* Prestar atenção para bolt-ons indiferenciados — Os modelos que ganharam a atenção da mídia são extremamente novos e, embora certamente estejamos vendo rodadas extremamente rápidas de experimentação e inovação, construir produtos valiosos leva tempo (e pesquisa, validação e teste). Esperamos ver muitos truques enigmáticos do ChatGPT nos próximos meses. Ao avaliar soluções que reivindicam integração com esses modelos generativos de alto perfil, pergunte-se: o que o fornecedor está mostrando é exclusivo dele?\r\n\r\n\r\n** Principais tendências martech para 2023\r\n------------------------------------------------------------\r\nhttps://martechmap.com/int_supergraphic?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D\r\n\r\nCinco grandes tendências moldarão Martech e Marketing em 2023, na opinião de Scott Brinker, do chiefmartec.com e Frans Riemersma, do MartechTribe (https://youtu.be/eqHNjX_J090?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , responsáveis pela criação e manutenção anual do Martech Landscape (https://martechmap.com/int_supergraphic?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) (acima), hoje com 10.383 fornecedores divididos em 49 categorias. São elas IA Generativa, ativação de data warehouses em nuvem, comunidades e ecossistemas, criadores sem código e Web3 e o metaverso.\r\n\r\nDe acordo com eles, a geração atual de produtos martech foi amplamente suportada por três grandes movimentos, que geraram grandes mudanças no mundo, na indústria de tecnologia e na profissão de marketing: SaaS, social media e dispositivos móveis. Agora, novos movimentos influenciarão o que está por vir:\r\n1. IA — Aprendizado de Máquina (https://en.wikipedia.org/wiki/Machine_learning?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) avançado e onipresente, IA Generativa (https://en.wikipedia.org/wiki/Synthetic_media?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) (como ChatGPT e Stable Diffusion) e uma ascensão constante para IA Geral (a AGI) (https://en.wikipedia.org/wiki/Artificial_general_intelligence?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) mudarão radicalmente o que as máquinas poderão fazer, tanto para profissionais de Marketing quanto para os consumidores (https://chiefmartec.com/2020/12/martech-2030-trend-5-harmonizing-human-machine/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) ;\r\n2. Realidades Virtual e Aumentada — Remodelará completamente o que é possível com as experiências do cliente, desvinculadas das telas como as pensamos hoje;\r\n3. Composability — Por meio de APIs e no-code, o software se tornará muito mais maleável e permeável, enquanto os dados se tornarão muito mais fluidos e portáteis, permitindo que empresas e indivíduos “componham” facilmente soluções e/ou experiências personalizadas, em tempo real.\r\n4. Web3 — A descentralização e os ativos digitais permanentes e não replicáveis permitirão tipos muito diferentes de organizações e modelos de negócios.\r\n\r\nEsses movimentos farão com que os próximos sete anos na indústria e na profissão de martech superem os últimos sete anos em expansão, prevê Scott Brinker (https://chiefmartec.com/2023/01/2023-will-be-a-chaotic-year-for-martech-yet-the-start-of-a-massive-wave-of-growth/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n\r\n** PESQUISA\r\n------------------------------------------------------------\r\n\r\n\r\n** Depois de sete anos, um humano derrota a IA no Go\r\n------------------------------------------------------------\r\n\r\nForam, a todo, 15 partidas, mas, dessa vez, a IA só venceu uma (https://arstechnica.com/information-technology/2023/02/man-beats-machine-at-go-in-human-victory-over-ai/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . E o humano não era nenhum jogador profissional. Muito menos um campeão mundial. A tática de Kellin Pelrine para derrotar a máquina? Explorar uma falha no sistema, recém descoberta por outro computador. Uma espécie de ponto cego, que deu o jogador humano a vantagem necessária para superar a IA.\r\n\r\nPelrine criou um grande \"loop\" de pedras para cercar um grupo de pedras de seu oponente e depois distraí-lo fazendo movimentos em outras áreas do tabuleiro. Mesmo quando seu grupo estava quase cercado, o sistema não percebeu a estratégia. Algo que para jogadores humanos seria de fácil percepção, já que as pedras circundantes se destacam no tabuleiro.\r\n\r\nOK. Pelrine não chegou a enfrentar o AlphaGo, o sistema desenvolvido pela DeepMind, que derrotou o campeão mundial de Go Lee Sedol por quatro jogos a um em 2016. Mas os sistemas contra os quais jogou são equivalentes.\r\n\r\nNo final do ano passado, um estudante de doutorado de Berkeley, Adam Gleave, trabalhando com o eminente cientista da computação de Berkeley, Stuart Russell, descobriu uma maneira específica de falsificar dois dos melhores programas de Go: o KataGo (https://arxiv.org/abs/2211.00241?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) e o Leela Zero. O que eles fizeram foi ensiná-la a Pelrine, que a colocou em prática durante os jogos.\r\n\r\nA descoberta dessa fraqueza em alguns sistemas Go-play mais avançadas aponta para uma falha fundamental dos algoritmos de Deep Learning que sustentam s aplicações mais avançada de hoje, afirma Russell. \"Esses sistemas podem apenas 'entender' situações específicas às quais foram expostos no passado, mas são incapazes de generalizar da forma que os humanos fazem\", explica.\r\n\r\nA vitória de Pelrine é um lembrete de que, independente de quão boa seja a IA baseada em Deep Learnig quando treinada em uma imensa quantidade de dados, nunca teremos certeza de que sistemas desse tipo poderão estender o que sabem a novas circunstâncias. Vale para o jogo de GO, como vale para muitos desafios dos veículos autônomos e do uso de chatbots de IA como o ChatGPT e o Bard para buscas.\r\n* A propósito... a mais recente IA da DeepMind derrotou humanos no jogo Stratego (https://singularityhub.com/2022/12/05/deepminds-latest-ai-trounces-human-players-at-the-game-stratego/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , mais complicado para as máquinas do que xadrez ou Go.\r\n\r\n\r\n** Garimpo do dia\r\n------------------------------------------------------------\r\n* A Amazon Web Services e a Hugging Face anunciaram uma expansão de sua parceria (https://huggingface.co/blog/aws-partnership?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) que levará à construção de um modelo de linguagem de última geração na AWS (https://www.latimes.com/business/story/2023-02-21/amazons-aws-hugging-face-ai-deals-chatgpt?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) . Um concorrente do ChatGPT, disponibilizado pela AWS com outros produtos Hugging Face para que seus usuários criem seus próprios aplicativos.\r\n\r\n* 49 ferramentas de IA que não são ChatGPT, mas você precisa conhecer (https://media.licdn.com/dms/document/C561FAQEAFOWr5hfMDw/feedshare-document-pdf-analyzed/0/1677054156158?e=1677715200&v=beta&t=hXMH29kVrgpLgJYwmvrFumdV14GNJKh82Jbx9Funiuo&utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Atenção: a empresa espanhola Eliminalia garante que “apaga o seu passado” da internet. Mas seus métodos são duvidosos (https://www.theguardian.com/world/2023/feb/17/spanish-firm-erase-past-internet-eliminalia-web?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Como usar o ChatGPT para automatizar totalmente o data scraping (https://medium.com/codingthesmartway-com-blog/how-to-use-chatgpt-to-fully-automate-web-scraping-6bb0dab97943?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)  de páginas web?\r\n\r\n* Você já usa o Grammarly? Pois saiba que além de checar seus textos, ele também pode ajustar LLMs com os dados aos quais tem acesso (https://www.emergingtechbrew.com/stories/2023/02/09/grammarly-s-plans-for-the-generative-ai-boom?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Pesquisadores tentaram descobrir se a IA estaria criando sua própria linguagem. E chegaram a um primeiro veredito (https://www.lifewire.com/experts-wonder-if-ai-is-creating-its-own-language-5409230?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* Artistas acabam de ganhar uma ferramenta capaz de identificar obras geradas por IA que copiem seu estilo: a Glaze (http://glaze.cs.uchicago.edu/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) .\r\n\r\n* O Copilot for Business já está acessível a todos que quiserem usá-lo (https://techcrunch.com/2023/02/14/githubs-copilot-for-business-is-now-generally-available/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D) , avisa o GitHub.\r\n\r\nRECEBA NOSSAS NEWSLETTERS (https://theshift.info/newsletter/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n\r\n============================================================\r\n Esta mensagem foi enviada para bernarducs@gmail.com. ** Atualize suas preferências (https://www.theshift.info/assinatura/meus-dados/?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique ** aqui (https://theshift.us20.list-manage.com/unsubscribe?u=ea84232681227c5ec7971f469&id=7f93052ef8&e=43a197caaf&c=c7227b54e1)\r\n.\r\nVeja nossa ** Política de Privacidade (https://www.theshift.info/about/privacy?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\ne ** Termos de Uso (http://www.theshift.info/about/use?utm_source=The+Shift+Newsletter&utm_campaign=c7227b54e1-EMAIL_CAMPAIGN_2023_02_16_06_29&utm_medium=email&utm_term=0_-c7227b54e1-%5BLIST_EMAIL_ID%5D)\r\n.\r\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\nComo sistemas de IA devem se comportar\n\n\n\nGrandes modelos de linguagem e a Singularidade | Maturidade no uso está em alta | Como surfar o hype generativo | Um humano derrota a IA no Go |\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n\r\n                            22/02/23  |  Assine The Shift  |  Abra no browser\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteligência Aumentada\n\r\nOFERECIMENTO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\nbernardo, bom dia!\r\n\nUsuários e empresas estão descobrindo que os grandes modelos de linguagem sofrem de inconsistências e, muitas vezes, não filtram conteúdos nocivos. Por isso, entendem que seu uso deve ser precedido de um debate sobre ética. Mas quem cria e aplica as regras necessárias? \nAinda nesta edição:  \n\nGrandes modelos de linguagem e a Singularidade\nMaturidade no uso está em alta, ainda bem \nComo surfar bem a onda do hype generativo\nDepois de sete anos, um humano derrota a IA no Go\n\nSe você quer apoiar as vítimas do Litoral Norte, segue a lista das instituições que participam deste mutirão e estão recebendo doações.\n\r\nBoa leitura.\r\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo sistemas de IA devem se comportar\n\nA corrida para incorporar ferramentas derivadas de grandes modelos de linguagem (como o GPT-3 e superiores) aos fluxos de trabalho das empresas já começou. Mas da mesma forma que a mídia americana descobriu semana passada, também os usuários corporativos já perceberam que esses modelos nem sempre são factuais ou logicamente consistentes; têm conhecimento de eventos ocorridos após o seu treinamento ou são capazes de evitar discurso de ódio e outros conteúdos nocivos, só para citar mazelas recorrentes. \nA OpenAI, criadora do ChatGPT, sempre enfatizou que ele ainda é apenas um projeto de pesquisa, em evolução constante à medida que recebe o feedback das pessoas. O que não impediu a Microsoft de integrá-lo a uma nova versão do Bing — e decepcionar, após relatos dos primeiros beta testers. A ponto de implementar restrições significativas — incluindo um limite de 50 respostas totais por dia, bem como cinco turnos de bate-papo por sessão — para tentar reprimir respostas desequilibradas que ela já sabia que ocorreriam.\nResultado: todo o hype em torno da IA Generativa e da incorporação dos chatbots às buscas aqueceu o debate sobre os riscos da IA, iniciando outra corrida, pela criação de regras e abordagens capazes de tornar ferramentas como o ChatGPT mais precisas, consistentes e atualizadas. \nEm Stanford, pesquisadores chegaram a três procedimentos (MEND, SERAC e ConCoRD) usados para filtrar as conexões neurais dos modelos e identificar quais precisam ser atualizados e/ou corrigidos. A intenção desses pesquisadores é conseguir editar comportamentos dos modelos. E, depois, tornar essa edição do modelo mais simples para os usuários. Por exemplo, seria bom especificar uma edição descrevendo-a em linguagem natural (“seja mais positivo sobre vacinas”) em vez de coletar um conjunto de dados de exemplos (por exemplo, uma série de declarações positivas sobre vacinas) com o qual treinar novamente o modelo.\nMas, na opinião da OpenAI, qualquer iniciativa nesse sentido precisa ser precedida de um debate maior o sobre quais regras devem ser aplicadas aos grandes modelos de linguagem e quem deve decidir criá-las e aplicá-las. Reflexões que já vem fazendo internamente.\nA empresa está trabalhando em um projeto experimental, apelidado de “Consensus Project”, no qual os pesquisadores da OpenAI estão analisando até que ponto as pessoas concordam ou discordam sobre diferentes informações geradas por seus modelos. O objetivo é ampliar os pontos de vista e as perspectivas representadas neles. \nA OpenAI acredita que conseguirá treinar modelos de IA para representar diferentes perspectivas e visões de mundo. Ou seja, em vez de ter um ChatGPT de tamanho único, pessoas e empresas poderiam usá-lo para gerar respostas alinhadas com suas próprias políticas. “É para lá que aspiramos chegar, mas será uma jornada longa e difícil chegar lá porque percebemos o quão desafiador é”, disseram dois de seus engenheiros. \nDesafiador e perigoso, convenhamos! Uma revisão recente de centenas de descrições de trabalho escritas usando o ChatGPT por Kieran Snyder, CEO da fabricante de software Textio, descobriu que quanto mais personalizado o prompt, mais atraente a saída da IA — e mais potencialmente tendenciosa.\nTalvez, por isso, Sam Altman, o CEO da OpenAI tenha tornado a defender publicamente a regulação da tecnologia por trás de seus modelos. “Embora seja tentador avançar rapidamente, a sociedade precisa de tempo para se adaptar a algo tão grande”, escreveu ele em uma série de tuítes neste domingo. Meses atrás, Mira Murati, CTO da OpenAI, também já havia dito em entrevista à revista Time que o ChatGPT deveria ser regulamentado, pois poderia ser mal utilizado. Na opinião deles, está claro que precisaremos da formulação de políticas na velocidade da IA. O que dificilmente acontecerá.\nA audiência da Suprema Corte esta semana, sobre a liberdade de expressão on-line, levanta a questão de saber se as respostas de pesquisa com IA são protegidas pela Seção 230. Hipoteticamente, a IA Generativa pode não estar coberta por essa lei que protege as empresas de tecnologia de serem responsabilizadas por conteúdo online postado e compartilhado pelos usuários, de acordo com uma breve declaração do juiz da Neil M. Gorsuch.\nEntão, parte da tarefa imediata de criar regras que tornem as ferramentas de IA Generativa mais precisas, consistentes e atualizadas caberemos próprios desenvolvedores. Dias atrás, a OpenAi decidiu publicar esclarecimentos sobre como o comportamento do ChatGPT é moldado e como planeja melhorá-lo. E prometeu não parar por aí. \nPlayers iniciantes, como Jasper, um redator baseado em IA que criou ferramentas em cima do GPT e gerou uma receita estimada em US$ 75 milhões no ano passado, também estão lutando para se manter acima da onda e no controle de seus produtos. Os debates em sua conferência sobre IA Generativa, realizada na semana passada, deixar isso bem claro. \nE você, o que está fazendo para tornar os modelos que usa mais confiáveis?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUM CONTEÚDO 7D ANALYITCS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiar, desconfiando\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO que faz as pessoas acreditarem nos resultados da IA? Segundo uma pesquisa do MIT, saber que a \"caixa preta\" (modelo/algoritmo) foi feita por pessoas que elas conhecem. À primeira vista, a descoberta parece contraintuitiva. Imaginamos que as pessoas querem conhecer detalhes de como o algoritmo foi elaborado, certo?\r\n\r\nO time, portanto, pesa mais. Ao que parece, é a confiança nas pessoas que supervisionaram os dados, e na equipe de tecnologia que criou o algoritmo, que pesam na balança quando se trata de confiar no uso corporativo da IA nos negócios.\nPor outro lado, é preciso lembrar que a IA é uma tecnologia em constante evolução. É necessário um diálogo contínuo entre os desenvolvedores, usuários e reguladores da tecnologia, de modo a garantir que os sistemas de IA sejam responsáveis e confiáveis.\nQue tal colocar um pouco de lenha na fogueira? A confiança, como descrita na pesquisa, acontece, vemos isso em muitos dos nossos clientes. Mas ela precisa, na nossa opinião, ser precedida de um período saudável de desconfiança, experimentação e muitas perguntas: \n\n“Os dados estão corretos?\"\n“Fizemos todas as perguntas?\"\n\"Estamos incluindo todo o ecossistema?\"\n\"Eliminamos todos os vieses?\"\n\nÉ o que sinaliza também o estudo The Path to AI Maturity 2023, da LXT. O estudo aponta que, em média, 46% de todos os projetos de IA ainda não atingem seus objetivos. Mas o sucesso (confiança+resultados) aumenta com a maturidade do uso das aplicações, após superar os desafios da implantação: equilibrar tecnologia (integração, dados de qualidade) e fatores humanos (talentos, treinamento).\nHá um dado muito interessante no estudo, sobre as diferentes taxas de fracasso dos projetos, por indústria. (gráfico acima). Manufatura e supply chain (uma das nossas especialidades) têm a menor taxa de fracasso (29%), porque já atravessaram as fases de questionamento e experimentação. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrandes modelos de linguagem e a Singularidade\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO professor Christopher Potts é presidente do Departamento de Linguística da Universidade de Stanford. Nesta palestra, ele descreve o impressionante progresso dos modelos de aprendizado de máquina baseados nos Transformers - conceito que teve um grande impacto no processamento da linguagem natural, levando ao desenvolvimento de produtos como o GPT-3 - e discute suas implicações na sociedade. De acordo com ele, vivemos a Era de Ouro da pesquisa de IA e grandes avanços ainda estão por vir. Ele também defende que um marco significativo foi alcançado nos últimos anos em direção à Singularidade, a partir da disponibilidade de uma gigantesca quantidade de dados para treinamento desses modelos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nINTELIGÊNCIA ARTIFICIAL\nMaturidade no uso está em alta, ainda bem\nFazer com que os chatbots de conversação de IA, como o Chat GPT, soem humanos e convincentes está se mostrando mais fácil do que torná-los precisos, como mostraram os tropeços de lançamento público do Bard (Alphabet) e do Bing (Microsoft). \nQuando os chatbots fazem crowdsourcing na internet para criar uma narrativa de IA, inevitavelmente você enfrenta 'questões de verdade' e preconceitos inerentes à internet. Não é de surpreender que dois terços dos 300 executivos americanos participantes do estudo \"Path to AI Maturity 2023\", da LXT, digam que sua necessidade de dados de alta qualidade está aumentando à medida que modelos famintos de IA continuam devorando dados de treinamento para melhorar.\nAs boas notícias do estudo? As organizações evoluíram em suas jornadas de IA, com 48% dos entrevistados classificando-se no nível maduro, aonde a IA está em produção ou já faz parte do DNA comercial. Para conseguir isso, quase metade vem investindo US$ 76 milhões ou mais, anualmente, em IA, enquanto apenas 1% dos entrevistados gasta US$ 1 milhão ou menos. E mais de 80% implementaram uma estratégia de dados para impulsionar o sucesso de suas iniciativas de IA.\nAs soluções de processamento de linguagem natural (NLP) e reconhecimento de fala/voz são os aplicativos de IA mais implantados (com exceção de dois segmentos: serviços financeiros e supply chain), seguidos por análises preditivas e IA de conversação (CAI). E mais de 90% dizem que fizeram um progresso bom ou excelente no gerenciamento do viés da IA. Será? “A importância da IA ​​responsável está no topo da mente da maioria das organizações”, comentou Phil Hall, diretor de crescimento da LXT. “Tanto que a diversidade nos dados e na força de trabalho por trás deles é essencial para 90% dos participantes do estudo. Prestar atenção a uma estratégia de dados de qualidade que suporta IA nunca foi tão crítico\", completa.\nPara a maioria dos executivos entrevistados, a IA já é o passo seguinte na evolução da computação moderna e uma continuidade dos agora familiares aplicativos de computador orientados a dados, ou seja, aprendizado de máquina e análise preditiva.  E a “IA generativa”, mais um passo no desenvolvimento da IA moderna, ou seja, estudo profundo ou análise estatística de grandes quantidades de dados. Os resultados não são perfeitos, mas são mais do que bons o suficiente para melhorar a velocidade e a eficiência em tarefas mais rotineiras ou repetitivas. E falhar faz parte do processo de aprendizado das equipes e dos próprios modelos em uso.\n\nGrandes escritórios de advocacia americanos estão usando uma ferramenta da OpenAI para pesquisar e escrever documentos legais. E estão satisfeitos com os resultados, apesar das falhas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPLICAÇÃO\nComo surfar bem a onda do hype generativo\nÉ um sonho ter sistemas que forneçam respostas corretas, inteligentemente, com conhecimento instantâneo e contexto em diferentes áreas do conhecimento. Mas é um pesadelo que esses sistemas possam dar respostas falsas com a mesma facilidade com que fornecem uma real. Portanto, LLM hoje significa uma revolução para as equipes de dados, obrigadas a equilibrar a promessa de conhecimento instantâneo com a necessidade de garantir proteção e confiabilidade.\nA Forrester acaba de publicar um relatório sobre IA Generativa (pago) no qual aconselha seus clientes corporativos a não ignorarem ou minimizarem seu impacto. Seria “um erro caro”. Em resumo, na opinião da consultoria, a IA Generativa apresenta uma oportunidade de aprimorar e até mesmo automatizar os processos de trabalho existentes em TI, Marketing, atendimento ao cliente e outras funções de negócios. E as empresas precisam começar a experimentá-la, cercando-se se todos os cuidados, começando pela escolha de fornecedores. Isso significa:\n\nFazer as perguntas difíceis - Que modelo(s) ou API(s) o fornecedor está realmente usando (por exemplo, Davinci-003, BERT, GPT-J)? Para quais tarefas específicas de PNL seu produto foi projetado e como o LLM se encaixa nesse processo? Há quanto tempo utiliza os LLMs e quais benefícios seus clientes observaram? Quais medidas estão em vigor para detectar conteúdo impróprio? Quanto controle seus clientes terão sobre a saída ou isso é totalmente regido pelo modelo? Como o LLM pode ser ajustado ou personalizado para lidar com casos de uso específicos do domínio?\r\n\t \nSaber que ter mais parâmetros não é necessariamente melhor - Para tarefas pontuais de treinamento (como treinar um modelo básico de linguagem natural ou gerar dados de treinamento off-line para uso por modelos menores), aproveitar os LLMs extremamente grandes faz todo o sentido. Para casos de uso online, no entanto, usar modelos muito grandes pode ser extremamente caro e, francamente, um exagero. Um LLM menor (1 a 10 bilhões de parâmetros) específico de domínio pode superar modelos maiores a um custo muito menor.\r\n\t \nPrestar atenção para bolt-ons indiferenciados — Os modelos que ganharam a atenção da mídia são extremamente novos e, embora certamente estejamos vendo rodadas extremamente rápidas de experimentação e inovação, construir produtos valiosos leva tempo (e pesquisa, validação e teste). Esperamos ver muitos truques enigmáticos do ChatGPT nos próximos meses. Ao avaliar soluções que reivindicam integração com esses modelos generativos de alto perfil, pergunte-se: o que o fornecedor está mostrando é exclusivo dele? \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipais tendências martech para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCinco grandes tendências moldarão Martech e Marketing em 2023, na opinião de Scott Brinker, do chiefmartec.com e Frans Riemersma, do MartechTribe, responsáveis pela criação e manutenção anual do Martech Landscape (acima), hoje com 10.383 fornecedores divididos em 49 categorias. São elas IA Generativa, ativação de data warehouses em nuvem, comunidades e ecossistemas, criadores sem código e Web3 e o metaverso. \nDe acordo com eles, a geração atual de produtos martech foi amplamente suportada por três grandes movimentos, que geraram grandes mudanças no mundo, na indústria de tecnologia e na profissão de marketing: SaaS, social media e dispositivos móveis. Agora, novos movimentos influenciarão o que está por vir:\n\nIA — Aprendizado de Máquina avançado e onipresente, IA Generativa (como ChatGPT e Stable Diffusion) e uma ascensão constante para IA Geral (a AGI) mudarão radicalmente o que as máquinas poderão fazer, tanto para profissionais de Marketing quanto para os consumidores;\nRealidades Virtual e Aumentada — Remodelará completamente o que é possível com as experiências do cliente, desvinculadas das telas como as pensamos hoje;\nComposability — Por meio de APIs e no-code, o software se tornará muito mais maleável e permeável, enquanto os dados se tornarão muito mais fluidos e portáteis, permitindo que empresas e indivíduos “componham” facilmente soluções e/ou experiências personalizadas, em tempo real.\nWeb3 — A descentralização e os ativos digitais permanentes e não replicáveis permitirão tipos muito diferentes de organizações e modelos de negócios.\n\nEsses movimentos farão com que os próximos sete anos na indústria e na profissão de martech superem os últimos sete anos em expansão, prevê Scott Brinker.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPESQUISA\nDepois de sete anos, um humano derrota a IA no Go\nForam, a todo, 15 partidas, mas, dessa vez, a IA só venceu uma. E o humano não era nenhum jogador profissional. Muito menos um campeão mundial. A tática de Kellin Pelrine para derrotar a máquina? Explorar uma falha no sistema, recém descoberta por outro computador. Uma espécie de ponto cego, que deu o jogador humano a vantagem necessária para superar a IA.\nPelrine criou um grande \"loop\" de pedras para cercar um grupo de pedras de seu oponente e depois distraí-lo fazendo movimentos em outras áreas do tabuleiro. Mesmo quando seu grupo estava quase cercado, o sistema não percebeu a estratégia. Algo que para jogadores humanos seria de fácil percepção, já que as pedras circundantes se destacam no tabuleiro.\nOK. Pelrine não chegou a enfrentar o AlphaGo, o sistema desenvolvido pela DeepMind, que derrotou o campeão mundial de Go Lee Sedol por quatro jogos a um em 2016. Mas os sistemas contra os quais jogou são equivalentes.\nNo final do ano passado, um estudante de doutorado de Berkeley, Adam Gleave, trabalhando com o eminente cientista da computação de Berkeley, Stuart Russell, descobriu uma maneira específica de falsificar dois dos melhores programas de Go: o KataGo e o Leela Zero. O que eles fizeram foi ensiná-la a Pelrine, que a colocou em prática durante os jogos.\nA descoberta dessa fraqueza em alguns sistemas Go-play mais avançadas aponta para uma falha fundamental dos algoritmos de Deep Learning que sustentam s aplicações mais avançada de hoje, afirma Russell. \"Esses sistemas podem apenas 'entender' situações específicas às quais foram expostos no passado, mas são incapazes de generalizar da forma que os humanos fazem\", explica.\nA vitória de Pelrine é um lembrete de que, independente de quão boa seja a IA baseada em Deep Learnig quando treinada em uma imensa quantidade de dados, nunca teremos certeza de que sistemas desse tipo poderão estender o que sabem a novas circunstâncias. Vale para o jogo de GO, como vale para muitos desafios dos veículos autônomos e do uso de chatbots de IA como o ChatGPT e o Bard para buscas. \n\nA propósito... a mais recente IA da DeepMind derrotou humanos no jogo Stratego, mais complicado para as máquinas do que xadrez ou Go.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGarimpo do dia\n\nA Amazon Web Services e a Hugging Face anunciaram uma expansão de sua parceria que levará à construção de um modelo de linguagem de última geração na AWS. Um concorrente do ChatGPT, disponibilizado pela AWS com outros produtos Hugging Face para que seus usuários criem seus próprios aplicativos.\r\n\t \n49 ferramentas de IA que não são ChatGPT, mas você precisa conhecer. \r\n\t \nAtenção: a empresa espanhola Eliminalia garante que “apaga o seu passado” da internet. Mas seus métodos são duvidosos.\r\n\t \nComo usar o ChatGPT para automatizar totalmente o data scraping de páginas web?\r\n\t \nVocê já usa o Grammarly? Pois saiba que além de checar seus textos, ele também pode ajustar LLMs com os dados aos quais tem acesso.\r\n\t \nPesquisadores tentaram descobrir se a IA estaria criando sua própria linguagem. E chegaram a um primeiro veredito.\r\n\t \nArtistas acabam de ganhar uma ferramenta capaz de identificar obras geradas por IA que copiem seu estilo: a Glaze.\r\n\t \nO Copilot for Business já está acessível a todos que quiserem usá-lo, avisa o GitHub.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRECEBA NOSSAS NEWSLETTERS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\n Esta mensagem foi enviada para bernarducs@gmail.com. Atualize suas preferências.\r\nVocê pode se descadastrar de TODAS as newsletters com um único clique aqui.\r\n\r\nVeja nossa Política de Privacidade e Termos de Uso.\nCopyright © 2023 The Shift, todos os direitos reservados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}